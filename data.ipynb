{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek jumlah beserta struktur datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China_Drone -> Train Images: 2401, Test Images: 0, Annotations: 2401\n",
      "China_MotorBike -> Train Images: 1977, Test Images: 500, Annotations: 1977\n",
      "Czech -> Train Images: 2829, Test Images: 709, Annotations: 2829\n",
      "India -> Train Images: 7706, Test Images: 1959, Annotations: 7706\n",
      "Japan -> Train Images: 10506, Test Images: 2627, Annotations: 10506\n",
      "Norway -> Train Images: 8161, Test Images: 2040, Annotations: 8161\n",
      "United_States -> Train Images: 4805, Test Images: 1200, Annotations: 4805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = \"D:\\Pothole Vision - AI Road Damage Detection\\dataset\\RDD2022_all_countries\"\n",
    "def count_files(path):\n",
    "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]) if os.path.exists(path) else 0\n",
    "\n",
    "summary = []\n",
    "\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if os.path.isdir(country_path):\n",
    "        train_images = count_files(os.path.join(country_path, \"train\", \"images\"))\n",
    "        test_images = count_files(os.path.join(country_path, \"test\", \"images\"))\n",
    "        xml_files = count_files(os.path.join(country_path, \"train\", \"annotations\", \"xmls\"))\n",
    "        summary.append(f\"{country} -> Train Images: {train_images}, Test Images: {test_images}, Annotations: {xml_files}\")\n",
    "\n",
    "for line in summary:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue #1 Folder test China_drone [SOLVED]\n",
    "China_drone tidak punya folder test, abaikan?\n",
    "Selanjutnya Saya akan split datset dari Train & Test menjadi Train, Test, & Val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue #2 Struktur dataset [SOLVED]\n",
    "Jika dataset DIGABUNG semua negara menjadi satu dataset besar:\n",
    "Keuntungan:\n",
    "\n",
    "Model akan lebih general karena belajar dari berbagai jenis jalan, cuaca, kamera.\n",
    "\n",
    "Bisa membantu jika nanti digunakan di Indonesia yang belum punya data.\n",
    "\n",
    "Jumlah data menjadi sangat besar (10.000++), sangat bagus untuk deep learning.\n",
    "\n",
    "Kekurangan:\n",
    "\n",
    "Bisa menyebabkan bias ke negara dengan data terbanyak (misalnya India, Japan).\n",
    "\n",
    "Anotasi antar negara mungkin memiliki inkonsistensi kecil (labeling style, noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekomendasi untuk kasus ini:\n",
    "Karena kamu akan pakai untuk Indonesia, tapi belum punya data lokal, maka:\n",
    "\n",
    "Gabungkan semua negara → latih model global, supaya kuat terhadap variasi.\n",
    "\n",
    "Simpan metadata negara asalnya → bisa dipakai untuk evaluasi per negara.\n",
    "\n",
    "Nanti, jika ada data Indonesia, kamu bisa fine-tune model global ke data lokal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label di semua dataset mentah:\n",
      "D10: 11830\n",
      "D00: 26016\n",
      "D20: 10617\n",
      "Repair: 1046\n",
      "D40: 6544\n",
      "Block crack: 3\n",
      "D44: 5057\n",
      "D01: 179\n",
      "D11: 45\n",
      "D50: 3581\n",
      "D43: 793\n",
      "D0w0: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "root_path = \"dataset/RDD2022_all_countries\"\n",
    "\n",
    "country_folders = [\n",
    "    \"China_Drone\", \"China_MotorBike\", \"Czech\",\n",
    "    \"India\", \"Japan\", \"Norway\", \"United_States\"\n",
    "]\n",
    "\n",
    "all_labels = []\n",
    "\n",
    "for country in country_folders:\n",
    "    annotation_folder = os.path.join(root_path, country, \"train\", \"annotations\", \"xmls\")\n",
    "    if os.path.exists(annotation_folder):\n",
    "        for filename in os.listdir(annotation_folder):\n",
    "            if filename.endswith('.xml'):\n",
    "                file_path = os.path.join(annotation_folder, filename)\n",
    "                try:\n",
    "                    tree = ET.parse(file_path)\n",
    "                    root = tree.getroot()\n",
    "                    for obj in root.findall('object'):\n",
    "                        label = obj.find('name').text.strip()\n",
    "                        all_labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error parsing {file_path}: {e}\")\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(\"Distribusi label di semua dataset mentah:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai.\n",
      "File XML dan gambar yang dihapus: 34711\n",
      "File XML yang dipertahankan: 3674\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "root_path = \"dataset/RDD2022_all_countries\"\n",
    "\n",
    "def clean_annotations(root_path, target_label='D40'):\n",
    "    removed_files = 0\n",
    "    kept_files = 0\n",
    "    for country in os.listdir(root_path):\n",
    "        country_path = os.path.join(root_path, country)\n",
    "        if not os.path.isdir(country_path):\n",
    "            continue\n",
    "\n",
    "        # Proses folder train annotations (ubah jika perlu val/test juga)\n",
    "        annotations_dir = os.path.join(country_path, 'train', 'annotations', 'xmls')\n",
    "        images_dir = os.path.join(country_path, 'train', 'images')\n",
    "\n",
    "        if not os.path.exists(annotations_dir):\n",
    "            print(f\"Folder anotasi tidak ditemukan: {annotations_dir}, dilewati.\")\n",
    "            continue\n",
    "\n",
    "        for xml_file in os.listdir(annotations_dir):\n",
    "            if not xml_file.endswith('.xml'):\n",
    "                continue\n",
    "\n",
    "            xml_path = os.path.join(annotations_dir, xml_file)\n",
    "            image_file = xml_file.replace('.xml', '.jpg')\n",
    "            image_path = os.path.join(images_dir, image_file)\n",
    "\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Cari objek yang labelnya bukan target_label, hapus mereka\n",
    "            objects = root.findall('object')\n",
    "            removed_objs = 0\n",
    "            for obj in objects:\n",
    "                label = obj.find('name').text.strip()\n",
    "                if label != target_label:\n",
    "                    root.remove(obj)\n",
    "                    removed_objs += 1\n",
    "\n",
    "            # Cek apakah setelah penghapusan masih ada objek\n",
    "            if len(root.findall('object')) == 0:\n",
    "                # Hapus XML dan gambarnya\n",
    "                os.remove(xml_path)\n",
    "                if os.path.exists(image_path):\n",
    "                    os.remove(image_path)\n",
    "                removed_files += 1\n",
    "            else:\n",
    "                # Simpan ulang XML yang sudah dibersihkan\n",
    "                tree.write(xml_path)\n",
    "                kept_files += 1\n",
    "\n",
    "    print(f\"Proses selesai.\")\n",
    "    print(f\"File XML dan gambar yang dihapus: {removed_files}\")\n",
    "    print(f\"File XML yang dipertahankan: {kept_files}\")\n",
    "\n",
    "clean_annotations(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset berhasil digabung dan displit.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Lokasi dataset dan output\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset\\\\RDD2022_all_countries\"\n",
    "output_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "train_val_split = 0.8  # 80% untuk train, 20% untuk val\n",
    "\n",
    "# Membuat direktori output\n",
    "os.makedirs(os.path.join(output_path, 'train', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'train', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'test', 'images'), exist_ok=True)\n",
    "\n",
    "# Metadata untuk csv\n",
    "metadata = []\n",
    "\n",
    "def copy_file(src_file, dest_file):\n",
    "    shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Proses per negara\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    images_path = os.path.join(country_path, 'train', 'images')\n",
    "    annotations_path = os.path.join(country_path, 'train', 'annotations', 'xmls')\n",
    "\n",
    "    if not os.path.exists(images_path) or not os.path.exists(annotations_path):\n",
    "        continue\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.jpg')])\n",
    "    annotation_files = sorted([f for f in os.listdir(annotations_path) if f.endswith('.xml')])\n",
    "\n",
    "    # Pastikan hanya file yang cocok (image dan XML) yang digunakan\n",
    "    matched_files = []\n",
    "    for image in image_files:\n",
    "        basename = os.path.splitext(image)[0]\n",
    "        if f\"{basename}.xml\" in annotation_files:\n",
    "            matched_files.append((image, f\"{basename}.xml\"))\n",
    "\n",
    "    for image, annotation in matched_files:\n",
    "        src_image = os.path.join(images_path, image)\n",
    "        src_annotation = os.path.join(annotations_path, annotation)\n",
    "\n",
    "        split = 'train' if random.random() < train_val_split else 'val'\n",
    "        dest_image = os.path.join(output_path, split, 'images', image)\n",
    "        dest_annotation = os.path.join(output_path, split, 'annotations', annotation)\n",
    "\n",
    "        copy_file(src_image, dest_image)\n",
    "        copy_file(src_annotation, dest_annotation)\n",
    "\n",
    "        metadata.append({'filename': image, 'country': country, 'split': split})\n",
    "\n",
    "    # Test set (copy ke test/images tanpa anotasi)\n",
    "    test_images_path = os.path.join(country_path, 'test', 'images')\n",
    "    if os.path.exists(test_images_path):\n",
    "        for test_img in os.listdir(test_images_path):\n",
    "            if test_img.endswith('.jpg'):\n",
    "                src_test_img = os.path.join(test_images_path, test_img)\n",
    "                dest_test_img = os.path.join(output_path, 'test', 'images', test_img)\n",
    "                copy_file(src_test_img, dest_test_img)\n",
    "\n",
    "# Simpan metadata\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df = metadata_df.sort_values(by=['split', 'country', 'filename'])\n",
    "metadata_df.to_csv(os.path.join(output_path, 'metadata.csv'), index=False)\n",
    "\n",
    "print(\"✅ Dataset berhasil digabung dan displit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Jumlah File per Split ===\n",
      "+-------+---------------+--------------------+\n",
      "| Split | Images (.jpg) | Annotations (.xml) |\n",
      "+-------+---------------+--------------------+\n",
      "| Train |     2951      |        2951        |\n",
      "|  Val  |      723      |        723         |\n",
      "| Test  |     9035      |         -          |\n",
      "+-------+---------------+--------------------+\n",
      "\n",
      "=== Distribusi Metadata per Split ===\n",
      "+-------+-------+\n",
      "| Split | Count |\n",
      "+-------+-------+\n",
      "| train | 2951  |\n",
      "|  val  |  723  |\n",
      "+-------+-------+\n",
      "\n",
      "=== Distribusi Metadata per Negara ===\n",
      "+-----------------+-------+\n",
      "|     Country     | Count |\n",
      "+-----------------+-------+\n",
      "|      India      | 1530  |\n",
      "|      Japan      | 1390  |\n",
      "|     Norway      |  256  |\n",
      "| China_MotorBike |  164  |\n",
      "|      Czech      |  154  |\n",
      "|  United_States  |  116  |\n",
      "|   China_Drone   |  64   |\n",
      "+-----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "\n",
    "def count_files(path, ext):\n",
    "    return len([f for f in os.listdir(path) if f.endswith(ext)]) if os.path.exists(path) else 0\n",
    "\n",
    "# Data jumlah file berdasarkan split\n",
    "data = {\n",
    "    'Split': ['Train', 'Val', 'Test'],\n",
    "    'Images (.jpg)': [\n",
    "        count_files(os.path.join(root_path, 'train', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'val', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'test', 'images'), '.jpg')\n",
    "    ],\n",
    "    'Annotations (.xml)': [\n",
    "        count_files(os.path.join(root_path, 'train', 'annotations'), '.xml'),\n",
    "        count_files(os.path.join(root_path, 'val', 'annotations'), '.xml'),\n",
    "        '-'  # Test tidak punya anotasi\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_split = pd.DataFrame(data)\n",
    "\n",
    "# Membaca metadata.csv\n",
    "metadata_path = os.path.join(root_path, 'metadata.csv')\n",
    "if os.path.exists(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    split_counts = metadata['split'].value_counts().reset_index()\n",
    "    split_counts.columns = ['Split', 'Count']\n",
    "\n",
    "    country_counts = metadata['country'].value_counts().reset_index()\n",
    "    country_counts.columns = ['Country', 'Count']\n",
    "\n",
    "    # Tampilkan tabel\n",
    "    print(\"=== Jumlah File per Split ===\")\n",
    "    print(tabulate(df_split, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Split ===\")\n",
    "    print(tabulate(split_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Negara ===\")\n",
    "    print(tabulate(country_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "else:\n",
    "    print(\"❌ File metadata.csv tidak ditemukan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checklist Sebelum Training\n",
    "-----------------------------------------\n",
    "| Langkah                      | Status |\n",
    "| ---------------------------- | ------ |\n",
    "| Label hanya `D40`            | ✅     |\n",
    "| Dataset bersih & rapi        | ✅     |\n",
    "| Split 80:20                  | ✅     |\n",
    "| Metadata terdokumentasi      | ✅     |\n",
    "| Format dataset per algoritma | 🔜     |\n",
    "| Training script siap pakai   | 🔜     |\n",
    "| Evaluasi & logging per model | 🔜     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Struktur direktori berhasil dibuat (kecuali SSD).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SOURCE_DATASET = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "TARGET_ROOT = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets\"\n",
    "\n",
    "os.makedirs(TARGET_ROOT, exist_ok=True)\n",
    "\n",
    "# Daftar algoritma, SSD dikecualikan karena formatnya berbeda\n",
    "algorithms = [\"yolov8\", \"retinanet\", \"cornernet\", \"coco\"]  # SSD akan diproses dengan script khusus\n",
    "\n",
    "for algo in algorithms:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(TARGET_ROOT, algo, split, \"images\"), exist_ok=True)\n",
    "        if split != \"test\":  # hanya train dan val yang memiliki annotation\n",
    "            os.makedirs(os.path.join(TARGET_ROOT, algo, split, \"annotations\"), exist_ok=True)\n",
    "\n",
    "print(\"✅ Struktur direktori berhasil dibuat (kecuali SSD).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Menyalin dataset untuk yolov8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8 - train images: 100%|██████████| 2951/2951 [00:15<00:00, 187.76it/s]\n",
      "yolov8 - train annotations: 100%|██████████| 2951/2951 [00:12<00:00, 240.84it/s]\n",
      "yolov8 - val images: 100%|██████████| 723/723 [00:04<00:00, 161.00it/s]\n",
      "yolov8 - val annotations: 100%|██████████| 723/723 [00:03<00:00, 207.95it/s]\n",
      "yolov8 - test images: 100%|██████████| 9035/9035 [00:58<00:00, 153.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Menyalin dataset untuk retinanet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retinanet - train images: 100%|██████████| 2951/2951 [00:08<00:00, 347.41it/s] \n",
      "retinanet - train annotations: 100%|██████████| 2951/2951 [00:05<00:00, 572.85it/s] \n",
      "retinanet - val images: 100%|██████████| 723/723 [00:00<00:00, 1028.99it/s]\n",
      "retinanet - val annotations: 100%|██████████| 723/723 [00:00<00:00, 1837.15it/s]\n",
      "retinanet - test images: 100%|██████████| 9035/9035 [00:12<00:00, 743.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Menyalin dataset untuk cornernet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cornernet - train images: 100%|██████████| 2951/2951 [00:02<00:00, 1081.20it/s]\n",
      "cornernet - train annotations: 100%|██████████| 2951/2951 [00:01<00:00, 2472.98it/s]\n",
      "cornernet - val images: 100%|██████████| 723/723 [00:00<00:00, 964.09it/s] \n",
      "cornernet - val annotations: 100%|██████████| 723/723 [00:00<00:00, 2672.98it/s]\n",
      "cornernet - test images: 100%|██████████| 9035/9035 [00:11<00:00, 791.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Menyalin dataset untuk coco...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coco - train images: 100%|██████████| 2951/2951 [00:06<00:00, 446.98it/s] \n",
      "coco - train annotations: 100%|██████████| 2951/2951 [00:02<00:00, 1201.40it/s]\n",
      "coco - val images: 100%|██████████| 723/723 [00:02<00:00, 317.09it/s] \n",
      "coco - val annotations: 100%|██████████| 723/723 [00:01<00:00, 522.19it/s]\n",
      "coco - test images: 100%|██████████| 9035/9035 [00:24<00:00, 368.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Semua data berhasil diduplikasi ke algoritma selain SSD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for algo in algorithms:\n",
    "    print(f\"\\n📁 Menyalin dataset untuk {algo}...\")\n",
    "    for split in splits:\n",
    "        src_img_dir = os.path.join(SOURCE_DATASET, split, \"images\")\n",
    "        dest_img_dir = os.path.join(TARGET_ROOT, algo, split, \"images\")\n",
    "        for f in tqdm(os.listdir(src_img_dir), desc=f\"{algo} - {split} images\"):\n",
    "            if f.endswith(\".jpg\"):\n",
    "                shutil.copy(os.path.join(src_img_dir, f), os.path.join(dest_img_dir, f))\n",
    "\n",
    "        if split != \"test\":\n",
    "            src_ann_dir = os.path.join(SOURCE_DATASET, split, \"annotations\")\n",
    "            dest_ann_dir = os.path.join(TARGET_ROOT, algo, split, \"annotations\")\n",
    "            for f in tqdm(os.listdir(src_ann_dir), desc=f\"{algo} - {split} annotations\"):\n",
    "                if f.endswith(\".xml\"):\n",
    "                    shutil.copy(os.path.join(src_ann_dir, f), os.path.join(dest_ann_dir, f))\n",
    "\n",
    "print(\"\\n✅ Semua data berhasil diduplikasi ke algoritma selain SSD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konversi annotation ke format:\n",
    "- YOLOv8      → .txt (YOLO format)\n",
    "- SSD         → TFRecord / COCO JSON\n",
    "- RetinaNet   → COCO JSON\n",
    "- Deformable DETR → COCO JSON\n",
    "- CornerNet   → COCO JSON (keypoint-style bounding box if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n",
      "| Algorithm | train_images | train_annotations | val_images | val_annotations | test_images | test_annotations |\n",
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n",
      "|  yolov8   |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "| retinanet |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "| cornernet |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "|   coco    |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "summary = []\n",
    "for algo in algorithms:\n",
    "    row = {\"Algorithm\": algo}\n",
    "    for split in splits:\n",
    "        img_dir = os.path.join(TARGET_ROOT, algo, split, \"images\")\n",
    "        ann_dir = os.path.join(TARGET_ROOT, algo, split, \"annotations\") if split != \"test\" else \"-\"\n",
    "        row[f\"{split}_images\"] = len(os.listdir(img_dir))\n",
    "        row[f\"{split}_annotations\"] = len(os.listdir(ann_dir)) if ann_dir != \"-\" else \"-\"\n",
    "    summary.append(row)\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YOLO] Converting train: 100%|██████████| 2951/2951 [00:03<00:00, 905.50it/s] \n",
      "[YOLO] Converting val: 100%|██████████| 723/723 [00:00<00:00, 1537.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Konversi YOLOv8 selesai. Untuk algoritma lain, dilanjutkan dengan modul terpisah.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Konversi anotasi XML (Pascal VOC) ke format masing-masing algoritma\n",
    "# Output disimpan di folder prepared-datasets/{algo}/\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset sumber\n",
    "SOURCE_IMAGES_DIR = \"dataset-mix\"\n",
    "SOURCE_ANN_DIR = {\n",
    "    'train': os.path.join(SOURCE_IMAGES_DIR, 'train', 'annotations'),\n",
    "    'val': os.path.join(SOURCE_IMAGES_DIR, 'val', 'annotations'),\n",
    "}\n",
    "\n",
    "# Target direktori per algoritma\n",
    "ALGORITHMS = ['yolov8', 'ssd', 'retinanet', 'coco', 'cornernet']\n",
    "PREPARED_ROOT = \"prepared-datasets\"\n",
    "\n",
    "# Pastikan direktori target tersedia\n",
    "def prepare_dirs():\n",
    "    for algo in ALGORITHMS:\n",
    "        for split in ['train', 'val']:\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'annotations'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'labels'), exist_ok=True)\n",
    "\n",
    "# Konversi ke format YOLOv8\n",
    "# Hanya menyimpan kelas D40 dengan index 0\n",
    "def convert_to_yolo():\n",
    "    for split in ['train', 'val']:\n",
    "        image_dir = os.path.join(SOURCE_IMAGES_DIR, split, 'images')\n",
    "        ann_dir = SOURCE_ANN_DIR[split]\n",
    "        target_img_dir = os.path.join(PREPARED_ROOT, 'yolov8', split, 'images')\n",
    "        target_label_dir = os.path.join(PREPARED_ROOT, 'yolov8', split, 'labels')\n",
    "\n",
    "        for file in tqdm(os.listdir(ann_dir), desc=f\"[YOLO] Converting {split}\"):\n",
    "            if not file.endswith(\".xml\"): continue\n",
    "            xml_path = os.path.join(ann_dir, file)\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            image_filename = root.find('filename').text\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "            out_image_path = os.path.join(target_img_dir, image_filename)\n",
    "\n",
    "            # Symlink image\n",
    "            if not os.path.exists(out_image_path):\n",
    "                os.symlink(os.path.abspath(image_path), out_image_path)\n",
    "\n",
    "            size = root.find(\"size\")\n",
    "            w, h = int(size.find(\"width\").text), int(size.find(\"height\").text)\n",
    "            yolo_lines = []\n",
    "\n",
    "            for obj in root.findall(\"object\"):\n",
    "                name = obj.find(\"name\").text.strip()\n",
    "                if name != \"D40\":\n",
    "                    continue  # Skip non-D40\n",
    "\n",
    "                bndbox = obj.find(\"bndbox\")\n",
    "                xmin = int(float(bndbox.find(\"xmin\").text))\n",
    "                ymin = int(float(bndbox.find(\"ymin\").text))\n",
    "                xmax = int(float(bndbox.find(\"xmax\").text))\n",
    "                ymax = int(float(bndbox.find(\"ymax\").text))\n",
    "\n",
    "                # Convert to YOLO format\n",
    "                x_center = ((xmin + xmax) / 2) / w\n",
    "                y_center = ((ymin + ymax) / 2) / h\n",
    "                bw = (xmax - xmin) / w\n",
    "                bh = (ymax - ymin) / h\n",
    "                yolo_lines.append(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "            # Simpan hasil label YOLO\n",
    "            txt_path = os.path.join(target_label_dir, file.replace(\".xml\", \".txt\"))\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prepare_dirs()\n",
    "    convert_to_yolo()\n",
    "    print(\"✅ Konversi YOLOv8 selesai. Untuk algoritma lain, dilanjutkan dengan modul terpisah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke SSD selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_ssd.py\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_ssd(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset yang sudah dalam VOC format ke struktur SSD:\n",
    "    - Annotations (XML)\n",
    "    - JPEGImages (images)\n",
    "    - ImageSets/Main/{train.txt,val.txt,test.txt}\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): folder dataset mix dengan struktur train/val/test\n",
    "        output_root (str): folder output konversi SSD\n",
    "    \"\"\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    ann_out = os.path.join(output_root, 'Annotations')\n",
    "    img_out = os.path.join(output_root, 'JPEGImages')\n",
    "    sets_main = os.path.join(output_root, 'ImageSets', 'Main')\n",
    "    os.makedirs(ann_out, exist_ok=True)\n",
    "    os.makedirs(img_out, exist_ok=True)\n",
    "    os.makedirs(sets_main, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        list_file = open(os.path.join(sets_main, f\"{split}.txt\"), 'w')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        img_dir = os.path.join(dataset_root, split, 'images')\n",
    "\n",
    "        for xml_file in os.listdir(ann_dir) if split != 'test' else []:\n",
    "            if not xml_file.endswith('.xml'):\n",
    "                continue\n",
    "            base_name = os.path.splitext(xml_file)[0]\n",
    "            # Copy annotation XML\n",
    "            shutil.copy(os.path.join(ann_dir, xml_file), os.path.join(ann_out, xml_file))\n",
    "            # Copy image\n",
    "            img_file = base_name + '.jpg'\n",
    "            shutil.copy(os.path.join(img_dir, img_file), os.path.join(img_out, img_file))\n",
    "            list_file.write(base_name + '\\n')\n",
    "\n",
    "        # For test split, no annotations, copy images only and write image IDs\n",
    "        if split == 'test':\n",
    "            for img_file in os.listdir(img_dir):\n",
    "                if not img_file.endswith('.jpg'):\n",
    "                    continue\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                shutil.copy(os.path.join(img_dir, img_file), os.path.join(img_out, img_file))\n",
    "                list_file.write(base_name + '\\n')\n",
    "\n",
    "        list_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/ssd\"\n",
    "    convert_to_ssd(dataset_root, output_root)\n",
    "    print(\"Konversi ke SSD selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke RetinaNet (COCO JSON) selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_retinanet.py\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_coco(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset VOC ke COCO JSON untuk RetinaNet.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): folder dataset mix (train/val/test)\n",
    "        output_root (str): folder output untuk JSON dan images (images di luar scope)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    categories = [\n",
    "        {\"id\": 1, \"name\": \"D40\"}\n",
    "    ]\n",
    "\n",
    "    def parse_xml(xml_path, image_id, annotation_id_start):\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": root.find('filename').text,\n",
    "            \"height\": int(root.find('size/height').text),\n",
    "            \"width\": int(root.find('size/width').text),\n",
    "        }\n",
    "        annotations = []\n",
    "        annotation_id = annotation_id_start\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text.strip()\n",
    "            if label != 'D40':  # Abaikan label selain D40\n",
    "                continue\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(float(bndbox.find('xmin').text))\n",
    "            ymin = int(float(bndbox.find('ymin').text))\n",
    "            xmax = int(float(bndbox.find('xmax').text))\n",
    "            ymax = int(float(bndbox.find('ymax').text))\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "\n",
    "            annotations.append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": [xmin, ymin, width, height],\n",
    "                \"area\": width * height,\n",
    "                \"iscrowd\": 0,\n",
    "            })\n",
    "            annotation_id += 1\n",
    "        return image_info, annotations, annotation_id\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        images_dir = os.path.join(dataset_root, split, 'images')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        json_out_path = os.path.join(output_root, f'{split}.json')\n",
    "\n",
    "        images = []\n",
    "        annotations = []\n",
    "        annotation_id = 1\n",
    "        image_id = 1\n",
    "\n",
    "        for img_file in os.listdir(images_dir):\n",
    "            if not img_file.endswith('.jpg'):\n",
    "                continue\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            xml_file = os.path.join(ann_dir, base_name + '.xml')\n",
    "\n",
    "            if split == 'test' or not os.path.exists(xml_file):\n",
    "                # Untuk test split, kita buat data image tanpa annotation\n",
    "                images.append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": img_file,\n",
    "                    \"height\": None,\n",
    "                    \"width\": None,\n",
    "                })\n",
    "                image_id += 1\n",
    "                continue\n",
    "\n",
    "            image_info, anns, annotation_id = parse_xml(xml_file, image_id, annotation_id)\n",
    "            if anns:\n",
    "                images.append(image_info)\n",
    "                annotations.extend(anns)\n",
    "            image_id += 1\n",
    "\n",
    "        coco_format = {\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations,\n",
    "            \"categories\": categories\n",
    "        }\n",
    "\n",
    "        with open(json_out_path, 'w') as f:\n",
    "            json.dump(coco_format, f, indent=4)\n",
    "\n",
    "    print(\"Konversi ke RetinaNet (COCO JSON) selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/retinanet\"\n",
    "    convert_to_coco(dataset_root, output_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR == RettinaNet\n",
    "Konversi ke format Deformable DETR (COCO JSON style, sama dengan RetinaNet)\n",
    "Karena Deformable DETR juga menggunakan COCO format, kamu bisa gunakan file JSON yang sama dari script RetinaNet di atas. Jadi cukup jalankan script convert_to_retinanet.py untuk kedua algoritma tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke CornerNet selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_cornernet.py\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_cornernet(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset VOC ke format JSON sederhana untuk CornerNet.\n",
    "\n",
    "    Format JSON yang dihasilkan:\n",
    "    {\n",
    "    \"images\": [\n",
    "        {\n",
    "            \"file_name\": \"image1.jpg\",\n",
    "            \"bboxes\": [[xmin, ymin, xmax, ymax], ...]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        images_dir = os.path.join(dataset_root, split, 'images')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        json_out_path = os.path.join(output_root, f'{split}.json')\n",
    "\n",
    "        data = {\"images\": []}\n",
    "\n",
    "        for img_file in os.listdir(images_dir):\n",
    "            if not img_file.endswith('.jpg'):\n",
    "                continue\n",
    "\n",
    "            img_info = {\"file_name\": img_file, \"bboxes\": []}\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            xml_file = os.path.join(ann_dir, base_name + '.xml')\n",
    "\n",
    "            if split != 'test' and os.path.exists(xml_file):\n",
    "                tree = ET.parse(xml_file)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for obj in root.findall('object'):\n",
    "                    label = obj.find('name').text.strip()\n",
    "                    if label != 'D40':  # Hanya kelas D40 yang diambil\n",
    "                        continue\n",
    "\n",
    "                    bndbox = obj.find('bndbox')\n",
    "                    xmin = int(float(bndbox.find('xmin').text))\n",
    "                    ymin = int(float(bndbox.find('ymin').text))\n",
    "                    xmax = int(float(bndbox.find('xmax').text))\n",
    "                    ymax = int(float(bndbox.find('ymax').text))\n",
    "                    img_info[\"bboxes\"].append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            data[\"images\"].append(img_info)\n",
    "\n",
    "        with open(json_out_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    print(\"Konversi ke CornerNet selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/cornernet\"\n",
    "    convert_to_cornernet(dataset_root, output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.136 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.135  Python-3.10.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-D402, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8n-D402, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 160.839.7 MB/s, size: 60.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Pothole Vision - AI Road Damage Detection\\prepared-datasets\\yolov8\\train\\labels.cache... 2951 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2951/2951 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 186.993.3 MB/s, size: 70.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pothole Vision - AI Road Damage Detection\\prepared-datasets\\yolov8\\val\\labels.cache... 723 images, 0 backgrounds, 0 corrupt: 100%|██████████| 723/723 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8n-D402\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1md:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8n-D402\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20       2.1G      2.259       3.41      1.714         22        640: 100%|██████████| 185/185 [00:36<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.282      0.202      0.161     0.0606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      2.02G      2.229      2.635      1.747         16        640: 100%|██████████| 185/185 [00:35<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305       0.33       0.25      0.194     0.0724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      2.04G      2.265      2.464      1.756         17        640: 100%|██████████| 185/185 [00:35<00:00,  5.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.273       0.19      0.142     0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      2.01G      2.245      2.384      1.756         13        640: 100%|██████████| 185/185 [00:35<00:00,  5.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.352      0.259      0.219      0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      2.03G      2.183       2.25      1.698         17        640: 100%|██████████| 185/185 [00:35<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.398      0.308       0.29      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      2.03G      2.152      2.206      1.692         22        640: 100%|██████████| 185/185 [00:36<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.411      0.316      0.292      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      2.04G      2.128      2.171      1.662         10        640: 100%|██████████| 185/185 [00:36<00:00,  5.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.427      0.348      0.326      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      2.03G      2.087      2.107      1.641         19        640: 100%|██████████| 185/185 [00:36<00:00,  5.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.435      0.349      0.356      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      2.03G      2.063       2.06      1.631         18        640: 100%|██████████| 185/185 [00:35<00:00,  5.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.452      0.377      0.369      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      2.01G      2.049      1.989      1.606         24        640: 100%|██████████| 185/185 [00:35<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:04<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.467      0.384      0.389      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      2.01G      2.036      1.975      1.647         28        640:  83%|████████▎ | 154/185 [00:29<00:06,  5.11it/s]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # Bisa ganti ke yolov8s.pt, yolov8m.pt, dll\n",
    "\n",
    "model.train(\n",
    "    data=\"yolo.yaml\",\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"yolov8n-D40\",\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # evaluasi otomatis pada validation set yang didefinisikan di data.yaml\n",
    "print(metrics)  # lihat summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan evaluasi model\n",
    "metrics = model.val()  # TANPA confusion=True\n",
    "\n",
    "# Ambil confusion matrix (jika tersedia)\n",
    "if hasattr(metrics, \"confusion_matrix\"):\n",
    "    cm = metrics.confusion_matrix  # numpy array\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "else:\n",
    "    print(\"Confusion matrix tidak tersedia di metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "cm_matrix = cm.matrix  # Ambil array 2D dari ConfusionMatrix\n",
    "classes = model.names  # Misalnya: ['D40']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='.0f', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "for root, dirs, files in os.walk(target_dir):\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[1].lower() in image_extensions:\n",
    "            path = os.path.join(root, file)\n",
    "            print(f\"🖼 Menampilkan: {file}\")\n",
    "            img = mpimg.imread(path)\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.imshow(img)\n",
    "            plt.title(file)\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = metrics.box.mp    # mean precision (float)\n",
    "mr = metrics.box.mr    # mean recall (float)\n",
    "map50 = metrics.box.map50  # mAP@0.5 (float)\n",
    "map5095 = metrics.box.map    # mAP@0.5:0.95 (float)\n",
    "f1_scores = metrics.box.f1  # list F1 score per kelas\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "\n",
    "print(f\"Precision (mean): {mp:.4f}\")\n",
    "print(f\"Recall (mean): {mr:.4f}\")\n",
    "print(f\"mAP@0.5: {map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {map5095:.4f}\")\n",
    "print(f\"F1-score (mean): {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model yang sudah kamu train\n",
    "model = YOLO('yolov8n.pt')  # sesuaikan path model terbaikmu\n",
    "\n",
    "# Fungsi untuk load gambar dari file input (misal file dialog atau path file langsung)\n",
    "def predict_from_file(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    # Resize lebih kecil agar lebih cepat\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    results = model(img_rgb)\n",
    "    \n",
    "    result_img = results[0].plot()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(result_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Contoh panggil fungsi dengan file input gambar\n",
    "predict_from_file(\"dataset-mix/train/images/United_States_000068.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
