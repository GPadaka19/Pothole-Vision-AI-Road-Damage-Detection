{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek jumlah beserta struktur datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China_Drone -> Train Images: 2401, Test Images: 0, Annotations: 2401\n",
      "China_MotorBike -> Train Images: 1977, Test Images: 500, Annotations: 1977\n",
      "Czech -> Train Images: 2829, Test Images: 709, Annotations: 2829\n",
      "India -> Train Images: 7706, Test Images: 1959, Annotations: 7706\n",
      "Japan -> Train Images: 10506, Test Images: 2627, Annotations: 10506\n",
      "Norway -> Train Images: 8161, Test Images: 2040, Annotations: 8161\n",
      "United_States -> Train Images: 4805, Test Images: 1200, Annotations: 4805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = \"D:\\Pothole Vision - AI Road Damage Detection\\dataset\\RDD2022_all_countries\"\n",
    "def count_files(path):\n",
    "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]) if os.path.exists(path) else 0\n",
    "\n",
    "summary = []\n",
    "\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if os.path.isdir(country_path):\n",
    "        train_images = count_files(os.path.join(country_path, \"train\", \"images\"))\n",
    "        test_images = count_files(os.path.join(country_path, \"test\", \"images\"))\n",
    "        xml_files = count_files(os.path.join(country_path, \"train\", \"annotations\", \"xmls\"))\n",
    "        summary.append(f\"{country} -> Train Images: {train_images}, Test Images: {test_images}, Annotations: {xml_files}\")\n",
    "\n",
    "for line in summary:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "China_drone tidak punya folder test, abaikan?\n",
    "Selanjutnya Saya akan split datset dari Train & Test menjadi Train, Test, & Val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jika dataset DIGABUNG semua negara menjadi satu dataset besar:\n",
    "Keuntungan:\n",
    "\n",
    "Model akan lebih general karena belajar dari berbagai jenis jalan, cuaca, kamera.\n",
    "\n",
    "Bisa membantu jika nanti digunakan di Indonesia yang belum punya data.\n",
    "\n",
    "Jumlah data menjadi sangat besar (10.000++), sangat bagus untuk deep learning.\n",
    "\n",
    "Kekurangan:\n",
    "\n",
    "Bisa menyebabkan bias ke negara dengan data terbanyak (misalnya India, Japan).\n",
    "\n",
    "Anotasi antar negara mungkin memiliki inkonsistensi kecil (labeling style, noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rekomendasi untuk kasus ini:\n",
    "Karena kamu akan pakai untuk Indonesia, tapi belum punya data lokal, maka:\n",
    "\n",
    "Gabungkan semua negara → latih model global, supaya kuat terhadap variasi.\n",
    "\n",
    "Simpan metadata negara asalnya → bisa dipakai untuk evaluasi per negara.\n",
    "\n",
    "Nanti, jika ada data Indonesia, kamu bisa fine-tune model global ke data lokal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset berhasil digabung dan di-split.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Lokasi dataset dan output\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset\\\\RDD2022_all_countries\"\n",
    "output_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "train_val_split = 0.8  # 80% untuk train, 20% untuk val\n",
    "\n",
    "# Membuat direktori output\n",
    "os.makedirs(os.path.join(output_path, 'train', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'train', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'test', 'images'), exist_ok=True)\n",
    "\n",
    "# Metadata untuk csv\n",
    "metadata = []\n",
    "\n",
    "def copy_file(src_file, dest_file):\n",
    "    shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Proses per negara\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    images_path = os.path.join(country_path, 'train', 'images')\n",
    "    annotations_path = os.path.join(country_path, 'train', 'annotations', 'xmls')\n",
    "\n",
    "    if not os.path.exists(images_path) or not os.path.exists(annotations_path):\n",
    "        continue\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.jpg')])\n",
    "    annotation_files = sorted([f for f in os.listdir(annotations_path) if f.endswith('.xml')])\n",
    "\n",
    "    for image, annotation in zip(image_files, annotation_files):\n",
    "        # Gunakan nama file apa adanya\n",
    "        src_image = os.path.join(images_path, image)\n",
    "        src_annotation = os.path.join(annotations_path, annotation)\n",
    "\n",
    "        split = 'train' if random.random() < train_val_split else 'val'\n",
    "        dest_image = os.path.join(output_path, split, 'images', image)\n",
    "        dest_annotation = os.path.join(output_path, split, 'annotations', annotation)\n",
    "\n",
    "        copy_file(src_image, dest_image)\n",
    "        copy_file(src_annotation, dest_annotation)\n",
    "\n",
    "        metadata.append({'filename': image, 'country': country, 'split': split})\n",
    "\n",
    "    # Test set\n",
    "    test_images_path = os.path.join(country_path, 'test', 'images')\n",
    "    if os.path.exists(test_images_path):\n",
    "        for test_img in os.listdir(test_images_path):\n",
    "            if test_img.endswith('.jpg'):\n",
    "                src_test_img = os.path.join(test_images_path, test_img)\n",
    "                dest_test_img = os.path.join(output_path, 'test', 'images', test_img)\n",
    "                copy_file(src_test_img, dest_test_img)\n",
    "\n",
    "# Simpan metadata\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df.to_csv(os.path.join(output_path, 'metadata.csv'), index=False)\n",
    "\n",
    "print(\"✅ Dataset berhasil diproses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Jumlah File per Split ===\n",
      "+-------+--------+-----------------+\n",
      "| Split | Images | XML Annotations |\n",
      "+-------+--------+-----------------+\n",
      "| Train | 30820  |      30820      |\n",
      "|  Val  |  7565  |      7565       |\n",
      "| Test  |  9035  |        -        |\n",
      "+-------+--------+-----------------+\n",
      "\n",
      "=== Distribusi Metadata per Split ===\n",
      "+-------+-------+\n",
      "| Split | Count |\n",
      "+-------+-------+\n",
      "| train | 30820 |\n",
      "|  val  | 7565  |\n",
      "+-------+-------+\n",
      "\n",
      "=== Distribusi Metadata per Negara ===\n",
      "+-----------------+-------+\n",
      "|     Country     | Count |\n",
      "+-----------------+-------+\n",
      "|      Japan      | 10506 |\n",
      "|     Norway      | 8161  |\n",
      "|      India      | 7706  |\n",
      "|  United_States  | 4805  |\n",
      "|      Czech      | 2829  |\n",
      "|   China_Drone   | 2401  |\n",
      "| China_MotorBike | 1977  |\n",
      "+-----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "\n",
    "def count_files(path, ext):\n",
    "    return len([f for f in os.listdir(path) if f.endswith(ext)]) if os.path.exists(path) else 0\n",
    "\n",
    "# Data jumlah file berdasarkan split\n",
    "data = {\n",
    "    'Split': ['Train', 'Val', 'Test'],\n",
    "    'Images': [\n",
    "        count_files(os.path.join(root_path, 'train', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'val', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'test', 'images'), '.jpg')\n",
    "    ],\n",
    "    'XML Annotations': [\n",
    "        count_files(os.path.join(root_path, 'train', 'annotations'), '.xml'),\n",
    "        count_files(os.path.join(root_path, 'val', 'annotations'), '.xml'),\n",
    "        '-'  # Test tidak memiliki anotasi\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_split = pd.DataFrame(data)\n",
    "\n",
    "# Membaca metadata.csv\n",
    "metadata_path = os.path.join(root_path, 'metadata.csv')\n",
    "if os.path.exists(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    split_counts = metadata['split'].value_counts().reset_index()\n",
    "    split_counts.columns = ['Split', 'Count']\n",
    "\n",
    "    country_counts = metadata['country'].value_counts().reset_index()\n",
    "    country_counts.columns = ['Country', 'Count']\n",
    "\n",
    "    # Tampilkan tabel\n",
    "    print(\"=== Jumlah File per Split ===\")\n",
    "    print(tabulate(df_split, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Split ===\")\n",
    "    print(tabulate(split_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Negara ===\")\n",
    "    print(tabulate(country_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "else:\n",
    "    print(\"File metadata.csv tidak ditemukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label di semua XML:\n",
      "D10: 11830\n",
      "D00: 26016\n",
      "D20: 10617\n",
      "Repair: 1046\n",
      "D40: 6544\n",
      "Block crack: 3\n",
      "D44: 5057\n",
      "D01: 179\n",
      "D11: 45\n",
      "D43: 793\n",
      "D50: 3581\n",
      "D0w0: 1\n",
      "\n",
      "⚠️ Ada label lain selain D00!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "root_path = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "annotation_paths = [\n",
    "    os.path.join(root_path, 'train', 'annotations'),\n",
    "    os.path.join(root_path, 'val', 'annotations')\n",
    "]\n",
    "\n",
    "all_labels = []\n",
    "\n",
    "# Loop seluruh file XML di train & val\n",
    "for folder in annotation_paths:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.xml'):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                label = obj.find('name').text.strip()\n",
    "                all_labels.append(label)\n",
    "\n",
    "# Hitung semua kemunculan label\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(\"Distribusi label di semua XML:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "if all(label == \"D00\" for label in label_counts):\n",
    "    print(\"\\n✅ Semua file hanya mengandung label D00.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Ada label lain selain D00!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38385, 31909, 6476)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Lokasi dataset\n",
    "root_path = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "annotation_dirs = [\n",
    "    os.path.join(root_path, 'train', 'annotations'),\n",
    "    os.path.join(root_path, 'val', 'annotations')\n",
    "]\n",
    "image_dirs = [\n",
    "    os.path.join(root_path, 'train', 'images'),\n",
    "    os.path.join(root_path, 'val', 'images')\n",
    "]\n",
    "\n",
    "# Inisialisasi counter\n",
    "total_xml = 0\n",
    "removed_count = 0\n",
    "\n",
    "# Loop direktori anotasi dan gambar\n",
    "for ann_dir, img_dir in zip(annotation_dirs, image_dirs):\n",
    "    for filename in os.listdir(ann_dir):\n",
    "        if not filename.endswith('.xml'):\n",
    "            continue\n",
    "\n",
    "        total_xml += 1\n",
    "        xml_path = os.path.join(ann_dir, filename)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        labels = [obj.find('name').text.strip() for obj in root.findall('object')]\n",
    "        if not labels or any(label != \"D00\" for label in labels):\n",
    "            # Hapus XML dan gambar\n",
    "            os.remove(xml_path)\n",
    "            image_file = filename.replace('.xml', '.jpg')\n",
    "            image_path = os.path.join(img_dir, image_file)\n",
    "            if os.path.exists(image_path):\n",
    "                os.remove(image_path)\n",
    "            removed_count += 1\n",
    "\n",
    "total_xml, removed_count, total_xml - removed_count  # before, removed, after count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+\n",
      "| Split | Images (.jpg) | Annotations (.xml) |\n",
      "+-------+---------------+--------------------+\n",
      "| Train |     5237      |        5237        |\n",
      "|  Val  |     1239      |        1239        |\n",
      "| Test  |     9035      |         -          |\n",
      "+-------+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(path, ext):\n",
    "    return len([f for f in os.listdir(path) if f.endswith(ext)]) if os.path.exists(path) else 0\n",
    "\n",
    "base = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "\n",
    "report = {\n",
    "    \"Split\": [],\n",
    "    \"Images (.jpg)\": [],\n",
    "    \"Annotations (.xml)\": []\n",
    "}\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_count = count_files(os.path.join(base, split, 'images'), '.jpg')\n",
    "    xml_count = count_files(os.path.join(base, split, 'annotations'), '.xml') if split != 'test' else '-'\n",
    "    \n",
    "    report[\"Split\"].append(split.capitalize())\n",
    "    report[\"Images (.jpg)\"].append(img_count)\n",
    "    report[\"Annotations (.xml)\"].append(xml_count)\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "df = pd.DataFrame(report)\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.yaml')  # atau ganti ke 'yolov8s.yaml' jika mau versi sedikit lebih besar\n",
    "\n",
    "model.train(\n",
    "    data='rdd2022.yaml',\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='yolov8_d00_only',\n",
    "    project='runs/train'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
