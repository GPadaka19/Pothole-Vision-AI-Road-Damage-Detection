{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek jumlah beserta struktur datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China_Drone -> Train Images: 2401, Test Images: 0, Annotations: 2401\n",
      "China_MotorBike -> Train Images: 1977, Test Images: 500, Annotations: 1977\n",
      "Czech -> Train Images: 2829, Test Images: 709, Annotations: 2829\n",
      "India -> Train Images: 7706, Test Images: 1959, Annotations: 7706\n",
      "Japan -> Train Images: 10506, Test Images: 2627, Annotations: 10506\n",
      "Norway -> Train Images: 8161, Test Images: 2040, Annotations: 8161\n",
      "United_States -> Train Images: 4805, Test Images: 1200, Annotations: 4805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = \"D:\\Pothole Vision - AI Road Damage Detection\\dataset\\RDD2022_all_countries\"\n",
    "def count_files(path):\n",
    "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]) if os.path.exists(path) else 0\n",
    "\n",
    "summary = []\n",
    "\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if os.path.isdir(country_path):\n",
    "        train_images = count_files(os.path.join(country_path, \"train\", \"images\"))\n",
    "        test_images = count_files(os.path.join(country_path, \"test\", \"images\"))\n",
    "        xml_files = count_files(os.path.join(country_path, \"train\", \"annotations\", \"xmls\"))\n",
    "        summary.append(f\"{country} -> Train Images: {train_images}, Test Images: {test_images}, Annotations: {xml_files}\")\n",
    "\n",
    "for line in summary:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue #1 Folder test China_drone [SOLVED]\n",
    "China_drone tidak punya folder test, abaikan?\n",
    "Selanjutnya Saya akan split datset dari Train & Test menjadi Train, Test, & Val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue #2 Struktur dataset [SOLVED]\n",
    "Jika dataset DIGABUNG semua negara menjadi satu dataset besar:\n",
    "Keuntungan:\n",
    "\n",
    "Model akan lebih general karena belajar dari berbagai jenis jalan, cuaca, kamera.\n",
    "\n",
    "Bisa membantu jika nanti digunakan di Indonesia yang belum punya data.\n",
    "\n",
    "Jumlah data menjadi sangat besar (10.000++), sangat bagus untuk deep learning.\n",
    "\n",
    "Kekurangan:\n",
    "\n",
    "Bisa menyebabkan bias ke negara dengan data terbanyak (misalnya India, Japan).\n",
    "\n",
    "Anotasi antar negara mungkin memiliki inkonsistensi kecil (labeling style, noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekomendasi untuk kasus ini:\n",
    "Karena kamu akan pakai untuk Indonesia, tapi belum punya data lokal, maka:\n",
    "\n",
    "Gabungkan semua negara ‚Üí latih model global, supaya kuat terhadap variasi.\n",
    "\n",
    "Simpan metadata negara asalnya ‚Üí bisa dipakai untuk evaluasi per negara.\n",
    "\n",
    "Nanti, jika ada data Indonesia, kamu bisa fine-tune model global ke data lokal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label di semua dataset mentah:\n",
      "D10: 11830\n",
      "D00: 26016\n",
      "D20: 10617\n",
      "Repair: 1046\n",
      "D40: 6544\n",
      "Block crack: 3\n",
      "D44: 5057\n",
      "D01: 179\n",
      "D11: 45\n",
      "D50: 3581\n",
      "D43: 793\n",
      "D0w0: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "root_path = \"dataset/RDD2022_all_countries\"\n",
    "\n",
    "country_folders = [\n",
    "    \"China_Drone\", \"China_MotorBike\", \"Czech\",\n",
    "    \"India\", \"Japan\", \"Norway\", \"United_States\"\n",
    "]\n",
    "\n",
    "all_labels = []\n",
    "\n",
    "for country in country_folders:\n",
    "    annotation_folder = os.path.join(root_path, country, \"train\", \"annotations\", \"xmls\")\n",
    "    if os.path.exists(annotation_folder):\n",
    "        for filename in os.listdir(annotation_folder):\n",
    "            if filename.endswith('.xml'):\n",
    "                file_path = os.path.join(annotation_folder, filename)\n",
    "                try:\n",
    "                    tree = ET.parse(file_path)\n",
    "                    root = tree.getroot()\n",
    "                    for obj in root.findall('object'):\n",
    "                        label = obj.find('name').text.strip()\n",
    "                        all_labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error parsing {file_path}: {e}\")\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(\"Distribusi label di semua dataset mentah:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai.\n",
      "File XML dan gambar yang dihapus: 34711\n",
      "File XML yang dipertahankan: 3674\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "root_path = \"dataset/RDD2022_all_countries\"\n",
    "\n",
    "def clean_annotations(root_path, target_label='D40'):\n",
    "    removed_files = 0\n",
    "    kept_files = 0\n",
    "    for country in os.listdir(root_path):\n",
    "        country_path = os.path.join(root_path, country)\n",
    "        if not os.path.isdir(country_path):\n",
    "            continue\n",
    "\n",
    "        # Proses folder train annotations (ubah jika perlu val/test juga)\n",
    "        annotations_dir = os.path.join(country_path, 'train', 'annotations', 'xmls')\n",
    "        images_dir = os.path.join(country_path, 'train', 'images')\n",
    "\n",
    "        if not os.path.exists(annotations_dir):\n",
    "            print(f\"Folder anotasi tidak ditemukan: {annotations_dir}, dilewati.\")\n",
    "            continue\n",
    "\n",
    "        for xml_file in os.listdir(annotations_dir):\n",
    "            if not xml_file.endswith('.xml'):\n",
    "                continue\n",
    "\n",
    "            xml_path = os.path.join(annotations_dir, xml_file)\n",
    "            image_file = xml_file.replace('.xml', '.jpg')\n",
    "            image_path = os.path.join(images_dir, image_file)\n",
    "\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Cari objek yang labelnya bukan target_label, hapus mereka\n",
    "            objects = root.findall('object')\n",
    "            removed_objs = 0\n",
    "            for obj in objects:\n",
    "                label = obj.find('name').text.strip()\n",
    "                if label != target_label:\n",
    "                    root.remove(obj)\n",
    "                    removed_objs += 1\n",
    "\n",
    "            # Cek apakah setelah penghapusan masih ada objek\n",
    "            if len(root.findall('object')) == 0:\n",
    "                # Hapus XML dan gambarnya\n",
    "                os.remove(xml_path)\n",
    "                if os.path.exists(image_path):\n",
    "                    os.remove(image_path)\n",
    "                removed_files += 1\n",
    "            else:\n",
    "                # Simpan ulang XML yang sudah dibersihkan\n",
    "                tree.write(xml_path)\n",
    "                kept_files += 1\n",
    "\n",
    "    print(f\"Proses selesai.\")\n",
    "    print(f\"File XML dan gambar yang dihapus: {removed_files}\")\n",
    "    print(f\"File XML yang dipertahankan: {kept_files}\")\n",
    "\n",
    "clean_annotations(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset berhasil digabung dan displit.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Lokasi dataset dan output\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset\\\\RDD2022_all_countries\"\n",
    "output_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "train_val_split = 0.8  # 80% untuk train, 20% untuk val\n",
    "\n",
    "# Membuat direktori output\n",
    "os.makedirs(os.path.join(output_path, 'train', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'train', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'val', 'annotations'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'test', 'images'), exist_ok=True)\n",
    "\n",
    "# Metadata untuk csv\n",
    "metadata = []\n",
    "\n",
    "def copy_file(src_file, dest_file):\n",
    "    shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Proses per negara\n",
    "for country in os.listdir(root_path):\n",
    "    country_path = os.path.join(root_path, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    images_path = os.path.join(country_path, 'train', 'images')\n",
    "    annotations_path = os.path.join(country_path, 'train', 'annotations', 'xmls')\n",
    "\n",
    "    if not os.path.exists(images_path) or not os.path.exists(annotations_path):\n",
    "        continue\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.jpg')])\n",
    "    annotation_files = sorted([f for f in os.listdir(annotations_path) if f.endswith('.xml')])\n",
    "\n",
    "    # Pastikan hanya file yang cocok (image dan XML) yang digunakan\n",
    "    matched_files = []\n",
    "    for image in image_files:\n",
    "        basename = os.path.splitext(image)[0]\n",
    "        if f\"{basename}.xml\" in annotation_files:\n",
    "            matched_files.append((image, f\"{basename}.xml\"))\n",
    "\n",
    "    for image, annotation in matched_files:\n",
    "        src_image = os.path.join(images_path, image)\n",
    "        src_annotation = os.path.join(annotations_path, annotation)\n",
    "\n",
    "        split = 'train' if random.random() < train_val_split else 'val'\n",
    "        dest_image = os.path.join(output_path, split, 'images', image)\n",
    "        dest_annotation = os.path.join(output_path, split, 'annotations', annotation)\n",
    "\n",
    "        copy_file(src_image, dest_image)\n",
    "        copy_file(src_annotation, dest_annotation)\n",
    "\n",
    "        metadata.append({'filename': image, 'country': country, 'split': split})\n",
    "\n",
    "    # Test set (copy ke test/images tanpa anotasi)\n",
    "    test_images_path = os.path.join(country_path, 'test', 'images')\n",
    "    if os.path.exists(test_images_path):\n",
    "        for test_img in os.listdir(test_images_path):\n",
    "            if test_img.endswith('.jpg'):\n",
    "                src_test_img = os.path.join(test_images_path, test_img)\n",
    "                dest_test_img = os.path.join(output_path, 'test', 'images', test_img)\n",
    "                copy_file(src_test_img, dest_test_img)\n",
    "\n",
    "# Simpan metadata\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df = metadata_df.sort_values(by=['split', 'country', 'filename'])\n",
    "metadata_df.to_csv(os.path.join(output_path, 'metadata.csv'), index=False)\n",
    "\n",
    "print(\"‚úÖ Dataset berhasil digabung dan displit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change\n",
    "- filename,source,split,width,height\n",
    "- rdd2022_train_000001.jpg,RDD2022,train,640,640\n",
    "- india_train_000002.jpg,India,train,1280,720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Jumlah File per Split ===\n",
      "+-------+---------------+--------------------+\n",
      "| Split | Images (.jpg) | Annotations (.xml) |\n",
      "+-------+---------------+--------------------+\n",
      "| Train |     2951      |        2951        |\n",
      "|  Val  |      723      |        723         |\n",
      "| Test  |     9035      |         -          |\n",
      "+-------+---------------+--------------------+\n",
      "\n",
      "=== Distribusi Metadata per Split ===\n",
      "+-------+-------+\n",
      "| Split | Count |\n",
      "+-------+-------+\n",
      "| train | 2951  |\n",
      "|  val  |  723  |\n",
      "+-------+-------+\n",
      "\n",
      "=== Distribusi Metadata per Negara ===\n",
      "+-----------------+-------+\n",
      "|     Country     | Count |\n",
      "+-----------------+-------+\n",
      "|      India      | 1530  |\n",
      "|      Japan      | 1390  |\n",
      "|     Norway      |  256  |\n",
      "| China_MotorBike |  164  |\n",
      "|      Czech      |  154  |\n",
      "|  United_States  |  116  |\n",
      "|   China_Drone   |  64   |\n",
      "+-----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "root_path = \"D:\\\\Pothole Vision - AI Road Damage Detection\\\\dataset-mix\"\n",
    "\n",
    "def count_files(path, ext):\n",
    "    return len([f for f in os.listdir(path) if f.endswith(ext)]) if os.path.exists(path) else 0\n",
    "\n",
    "# Data jumlah file berdasarkan split\n",
    "data = {\n",
    "    'Split': ['Train', 'Val', 'Test'],\n",
    "    'Images (.jpg)': [\n",
    "        count_files(os.path.join(root_path, 'train', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'val', 'images'), '.jpg'),\n",
    "        count_files(os.path.join(root_path, 'test', 'images'), '.jpg')\n",
    "    ],\n",
    "    'Annotations (.xml)': [\n",
    "        count_files(os.path.join(root_path, 'train', 'annotations'), '.xml'),\n",
    "        count_files(os.path.join(root_path, 'val', 'annotations'), '.xml'),\n",
    "        '-'  # Test tidak punya anotasi\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_split = pd.DataFrame(data)\n",
    "\n",
    "# Membaca metadata.csv\n",
    "metadata_path = os.path.join(root_path, 'metadata.csv')\n",
    "if os.path.exists(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    split_counts = metadata['split'].value_counts().reset_index()\n",
    "    split_counts.columns = ['Split', 'Count']\n",
    "\n",
    "    country_counts = metadata['country'].value_counts().reset_index()\n",
    "    country_counts.columns = ['Country', 'Count']\n",
    "\n",
    "    # Tampilkan tabel\n",
    "    print(\"=== Jumlah File per Split ===\")\n",
    "    print(tabulate(df_split, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Split ===\")\n",
    "    print(tabulate(split_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(\"\\n=== Distribusi Metadata per Negara ===\")\n",
    "    print(tabulate(country_counts, headers='keys', tablefmt='pretty', showindex=False))\n",
    "else:\n",
    "    print(\"‚ùå File metadata.csv tidak ditemukan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checklist Sebelum Training\n",
    "-----------------------------------------\n",
    "| Langkah                      | Status |\n",
    "| ---------------------------- | ------ |\n",
    "| Label hanya `D40`            | ‚úÖ     |\n",
    "| Dataset bersih & rapi        | ‚úÖ     |\n",
    "| Split 80:20                  | ‚úÖ     |\n",
    "| Metadata terdokumentasi      | ‚úÖ     |\n",
    "| Format dataset per algoritma | üîú     |\n",
    "| Training script siap pakai   | üîú     |\n",
    "| Evaluasi & logging per model | üîú     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Struktur direktori berhasil dibuat (kecuali SSD).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SOURCE_DATASET = \"D:/Pothole Vision - AI Road Damage Detection/8-dataset\"\n",
    "TARGET_ROOT = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets\"\n",
    "\n",
    "os.makedirs(TARGET_ROOT, exist_ok=True)\n",
    "\n",
    "# Daftar algoritma, SSD dikecualikan karena formatnya berbeda\n",
    "algorithms = [\"yolov8\", \"retinanet\", \"cornernet\", \"coco\"]  # SSD akan diproses dengan script khusus\n",
    "\n",
    "for algo in algorithms:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(TARGET_ROOT, algo, split, \"images\"), exist_ok=True)\n",
    "        if split != \"test\":  # hanya train dan val yang memiliki annotation\n",
    "            os.makedirs(os.path.join(TARGET_ROOT, algo, split, \"annotations\"), exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Struktur direktori berhasil dibuat (kecuali SSD).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Menyalin dataset untuk yolov8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8 - train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:15<00:00, 187.76it/s]\n",
      "yolov8 - train annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:12<00:00, 240.84it/s]\n",
      "yolov8 - val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:04<00:00, 161.00it/s]\n",
      "yolov8 - val annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:03<00:00, 207.95it/s]\n",
      "yolov8 - test images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9035/9035 [00:58<00:00, 153.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Menyalin dataset untuk retinanet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retinanet - train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:08<00:00, 347.41it/s] \n",
      "retinanet - train annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:05<00:00, 572.85it/s] \n",
      "retinanet - val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 1028.99it/s]\n",
      "retinanet - val annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 1837.15it/s]\n",
      "retinanet - test images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9035/9035 [00:12<00:00, 743.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Menyalin dataset untuk cornernet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cornernet - train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:02<00:00, 1081.20it/s]\n",
      "cornernet - train annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:01<00:00, 2472.98it/s]\n",
      "cornernet - val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 964.09it/s] \n",
      "cornernet - val annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 2672.98it/s]\n",
      "cornernet - test images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9035/9035 [00:11<00:00, 791.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Menyalin dataset untuk coco...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coco - train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:06<00:00, 446.98it/s] \n",
      "coco - train annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:02<00:00, 1201.40it/s]\n",
      "coco - val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:02<00:00, 317.09it/s] \n",
      "coco - val annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:01<00:00, 522.19it/s]\n",
      "coco - test images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9035/9035 [00:24<00:00, 368.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Semua data berhasil diduplikasi ke algoritma selain SSD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for algo in algorithms:\n",
    "    print(f\"\\nüìÅ Menyalin dataset untuk {algo}...\")\n",
    "    for split in splits:\n",
    "        src_img_dir = os.path.join(SOURCE_DATASET, split, \"images\")\n",
    "        dest_img_dir = os.path.join(TARGET_ROOT, algo, split, \"images\")\n",
    "        for f in tqdm(os.listdir(src_img_dir), desc=f\"{algo} - {split} images\"):\n",
    "            if f.endswith(\".jpg\"):\n",
    "                shutil.copy(os.path.join(src_img_dir, f), os.path.join(dest_img_dir, f))\n",
    "\n",
    "        if split != \"test\":\n",
    "            src_ann_dir = os.path.join(SOURCE_DATASET, split, \"annotations\")\n",
    "            dest_ann_dir = os.path.join(TARGET_ROOT, algo, split, \"annotations\")\n",
    "            for f in tqdm(os.listdir(src_ann_dir), desc=f\"{algo} - {split} annotations\"):\n",
    "                if f.endswith(\".xml\"):\n",
    "                    shutil.copy(os.path.join(src_ann_dir, f), os.path.join(dest_ann_dir, f))\n",
    "\n",
    "print(\"\\n‚úÖ Semua data berhasil diduplikasi ke algoritma selain SSD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konversi annotation ke format:\n",
    "- YOLOv8      ‚Üí .txt (YOLO format)\n",
    "- SSD         ‚Üí TFRecord / COCO JSON\n",
    "- RetinaNet   ‚Üí COCO JSON\n",
    "- Deformable DETR ‚Üí COCO JSON\n",
    "- CornerNet   ‚Üí COCO JSON (keypoint-style bounding box if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n",
      "| Algorithm | train_images | train_annotations | val_images | val_annotations | test_images | test_annotations |\n",
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n",
      "|  yolov8   |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "| retinanet |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "| cornernet |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "|   coco    |     2951     |       2951        |    723     |       723       |    9035     |        -         |\n",
      "+-----------+--------------+-------------------+------------+-----------------+-------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "summary = []\n",
    "for algo in algorithms:\n",
    "    row = {\"Algorithm\": algo}\n",
    "    for split in splits:\n",
    "        img_dir = os.path.join(TARGET_ROOT, algo, split, \"images\")\n",
    "        ann_dir = os.path.join(TARGET_ROOT, algo, split, \"annotations\") if split != \"test\" else \"-\"\n",
    "        row[f\"{split}_images\"] = len(os.listdir(img_dir))\n",
    "        row[f\"{split}_annotations\"] = len(os.listdir(ann_dir)) if ann_dir != \"-\" else \"-\"\n",
    "    summary.append(row)\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YOLO] Converting train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:03<00:00, 905.50it/s] \n",
      "[YOLO] Converting val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 1537.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Konversi YOLOv8 selesai. Untuk algoritma lain, dilanjutkan dengan modul terpisah.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Konversi anotasi XML (Pascal VOC) ke format masing-masing algoritma\n",
    "# Output disimpan di folder prepared-datasets/{algo}/\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset sumber\n",
    "SOURCE_IMAGES_DIR = \"dataset-mix\"\n",
    "SOURCE_ANN_DIR = {\n",
    "    'train': os.path.join(SOURCE_IMAGES_DIR, 'train', 'annotations'),\n",
    "    'val': os.path.join(SOURCE_IMAGES_DIR, 'val', 'annotations'),\n",
    "}\n",
    "\n",
    "# Target direktori per algoritma\n",
    "ALGORITHMS = ['yolov8', 'ssd', 'retinanet', 'coco', 'cornernet']\n",
    "PREPARED_ROOT = \"prepared-datasets\"\n",
    "\n",
    "# Pastikan direktori target tersedia\n",
    "def prepare_dirs():\n",
    "    for algo in ALGORITHMS:\n",
    "        for split in ['train', 'val']:\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'annotations'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(PREPARED_ROOT, algo, split, 'labels'), exist_ok=True)\n",
    "\n",
    "# Konversi ke format YOLOv8\n",
    "# Hanya menyimpan kelas D40 dengan index 0\n",
    "def convert_to_yolo():\n",
    "    for split in ['train', 'val']:\n",
    "        image_dir = os.path.join(SOURCE_IMAGES_DIR, split, 'images')\n",
    "        ann_dir = SOURCE_ANN_DIR[split]\n",
    "        target_img_dir = os.path.join(PREPARED_ROOT, 'yolov8', split, 'images')\n",
    "        target_label_dir = os.path.join(PREPARED_ROOT, 'yolov8', split, 'labels')\n",
    "\n",
    "        for file in tqdm(os.listdir(ann_dir), desc=f\"[YOLO] Converting {split}\"):\n",
    "            if not file.endswith(\".xml\"): continue\n",
    "            xml_path = os.path.join(ann_dir, file)\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            image_filename = root.find('filename').text\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "            out_image_path = os.path.join(target_img_dir, image_filename)\n",
    "\n",
    "            # Symlink image\n",
    "            if not os.path.exists(out_image_path):\n",
    "                os.symlink(os.path.abspath(image_path), out_image_path)\n",
    "\n",
    "            size = root.find(\"size\")\n",
    "            w, h = int(size.find(\"width\").text), int(size.find(\"height\").text)\n",
    "            yolo_lines = []\n",
    "\n",
    "            for obj in root.findall(\"object\"):\n",
    "                name = obj.find(\"name\").text.strip()\n",
    "                if name != \"D40\":\n",
    "                    continue  # Skip non-D40\n",
    "\n",
    "                bndbox = obj.find(\"bndbox\")\n",
    "                xmin = int(float(bndbox.find(\"xmin\").text))\n",
    "                ymin = int(float(bndbox.find(\"ymin\").text))\n",
    "                xmax = int(float(bndbox.find(\"xmax\").text))\n",
    "                ymax = int(float(bndbox.find(\"ymax\").text))\n",
    "\n",
    "                # Convert to YOLO format\n",
    "                x_center = ((xmin + xmax) / 2) / w\n",
    "                y_center = ((ymin + ymax) / 2) / h\n",
    "                bw = (xmax - xmin) / w\n",
    "                bh = (ymax - ymin) / h\n",
    "                yolo_lines.append(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "            # Simpan hasil label YOLO\n",
    "            txt_path = os.path.join(target_label_dir, file.replace(\".xml\", \".txt\"))\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prepare_dirs()\n",
    "    convert_to_yolo()\n",
    "    print(\"‚úÖ Konversi YOLOv8 selesai. Untuk algoritma lain, dilanjutkan dengan modul terpisah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke SSD selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_ssd.py\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_ssd(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset yang sudah dalam VOC format ke struktur SSD:\n",
    "    - Annotations (XML)\n",
    "    - JPEGImages (images)\n",
    "    - ImageSets/Main/{train.txt,val.txt,test.txt}\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): folder dataset mix dengan struktur train/val/test\n",
    "        output_root (str): folder output konversi SSD\n",
    "    \"\"\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    ann_out = os.path.join(output_root, 'Annotations')\n",
    "    img_out = os.path.join(output_root, 'JPEGImages')\n",
    "    sets_main = os.path.join(output_root, 'ImageSets', 'Main')\n",
    "    os.makedirs(ann_out, exist_ok=True)\n",
    "    os.makedirs(img_out, exist_ok=True)\n",
    "    os.makedirs(sets_main, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        list_file = open(os.path.join(sets_main, f\"{split}.txt\"), 'w')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        img_dir = os.path.join(dataset_root, split, 'images')\n",
    "\n",
    "        for xml_file in os.listdir(ann_dir) if split != 'test' else []:\n",
    "            if not xml_file.endswith('.xml'):\n",
    "                continue\n",
    "            base_name = os.path.splitext(xml_file)[0]\n",
    "            # Copy annotation XML\n",
    "            shutil.copy(os.path.join(ann_dir, xml_file), os.path.join(ann_out, xml_file))\n",
    "            # Copy image\n",
    "            img_file = base_name + '.jpg'\n",
    "            shutil.copy(os.path.join(img_dir, img_file), os.path.join(img_out, img_file))\n",
    "            list_file.write(base_name + '\\n')\n",
    "\n",
    "        # For test split, no annotations, copy images only and write image IDs\n",
    "        if split == 'test':\n",
    "            for img_file in os.listdir(img_dir):\n",
    "                if not img_file.endswith('.jpg'):\n",
    "                    continue\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                shutil.copy(os.path.join(img_dir, img_file), os.path.join(img_out, img_file))\n",
    "                list_file.write(base_name + '\\n')\n",
    "\n",
    "        list_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/ssd\"\n",
    "    convert_to_ssd(dataset_root, output_root)\n",
    "    print(\"Konversi ke SSD selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke RetinaNet (COCO JSON) selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_retinanet.py\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_coco(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset VOC ke COCO JSON untuk RetinaNet.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): folder dataset mix (train/val/test)\n",
    "        output_root (str): folder output untuk JSON dan images (images di luar scope)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    categories = [\n",
    "        {\"id\": 1, \"name\": \"D40\"}\n",
    "    ]\n",
    "\n",
    "    def parse_xml(xml_path, image_id, annotation_id_start):\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": root.find('filename').text,\n",
    "            \"height\": int(root.find('size/height').text),\n",
    "            \"width\": int(root.find('size/width').text),\n",
    "        }\n",
    "        annotations = []\n",
    "        annotation_id = annotation_id_start\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text.strip()\n",
    "            if label != 'D40':  # Abaikan label selain D40\n",
    "                continue\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(float(bndbox.find('xmin').text))\n",
    "            ymin = int(float(bndbox.find('ymin').text))\n",
    "            xmax = int(float(bndbox.find('xmax').text))\n",
    "            ymax = int(float(bndbox.find('ymax').text))\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "\n",
    "            annotations.append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": [xmin, ymin, width, height],\n",
    "                \"area\": width * height,\n",
    "                \"iscrowd\": 0,\n",
    "            })\n",
    "            annotation_id += 1\n",
    "        return image_info, annotations, annotation_id\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        images_dir = os.path.join(dataset_root, split, 'images')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        json_out_path = os.path.join(output_root, f'{split}.json')\n",
    "\n",
    "        images = []\n",
    "        annotations = []\n",
    "        annotation_id = 1\n",
    "        image_id = 1\n",
    "\n",
    "        for img_file in os.listdir(images_dir):\n",
    "            if not img_file.endswith('.jpg'):\n",
    "                continue\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            xml_file = os.path.join(ann_dir, base_name + '.xml')\n",
    "\n",
    "            if split == 'test' or not os.path.exists(xml_file):\n",
    "                # Untuk test split, kita buat data image tanpa annotation\n",
    "                images.append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": img_file,\n",
    "                    \"height\": None,\n",
    "                    \"width\": None,\n",
    "                })\n",
    "                image_id += 1\n",
    "                continue\n",
    "\n",
    "            image_info, anns, annotation_id = parse_xml(xml_file, image_id, annotation_id)\n",
    "            if anns:\n",
    "                images.append(image_info)\n",
    "                annotations.extend(anns)\n",
    "            image_id += 1\n",
    "\n",
    "        coco_format = {\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations,\n",
    "            \"categories\": categories\n",
    "        }\n",
    "\n",
    "        with open(json_out_path, 'w') as f:\n",
    "            json.dump(coco_format, f, indent=4)\n",
    "\n",
    "    print(\"Konversi ke RetinaNet (COCO JSON) selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/retinanet\"\n",
    "    convert_to_coco(dataset_root, output_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR == RettinaNet\n",
    "Konversi ke format Deformable DETR (COCO JSON style, sama dengan RetinaNet)\n",
    "Karena Deformable DETR juga menggunakan COCO format, kamu bisa gunakan file JSON yang sama dari script RetinaNet di atas. Jadi cukup jalankan script convert_to_retinanet.py untuk kedua algoritma tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi ke CornerNet selesai.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_cornernet.py\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_cornernet(dataset_root, output_root):\n",
    "    \"\"\"\n",
    "    Konversi dataset VOC ke format JSON sederhana untuk CornerNet.\n",
    "\n",
    "    Format JSON yang dihasilkan:\n",
    "    {\n",
    "    \"images\": [\n",
    "        {\n",
    "            \"file_name\": \"image1.jpg\",\n",
    "            \"bboxes\": [[xmin, ymin, xmax, ymax], ...]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        images_dir = os.path.join(dataset_root, split, 'images')\n",
    "        ann_dir = os.path.join(dataset_root, split, 'annotations')\n",
    "        json_out_path = os.path.join(output_root, f'{split}.json')\n",
    "\n",
    "        data = {\"images\": []}\n",
    "\n",
    "        for img_file in os.listdir(images_dir):\n",
    "            if not img_file.endswith('.jpg'):\n",
    "                continue\n",
    "\n",
    "            img_info = {\"file_name\": img_file, \"bboxes\": []}\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            xml_file = os.path.join(ann_dir, base_name + '.xml')\n",
    "\n",
    "            if split != 'test' and os.path.exists(xml_file):\n",
    "                tree = ET.parse(xml_file)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for obj in root.findall('object'):\n",
    "                    label = obj.find('name').text.strip()\n",
    "                    if label != 'D40':  # Hanya kelas D40 yang diambil\n",
    "                        continue\n",
    "\n",
    "                    bndbox = obj.find('bndbox')\n",
    "                    xmin = int(float(bndbox.find('xmin').text))\n",
    "                    ymin = int(float(bndbox.find('ymin').text))\n",
    "                    xmax = int(float(bndbox.find('xmax').text))\n",
    "                    ymax = int(float(bndbox.find('ymax').text))\n",
    "                    img_info[\"bboxes\"].append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            data[\"images\"].append(img_info)\n",
    "\n",
    "        with open(json_out_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    print(\"Konversi ke CornerNet selesai.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"D:/Pothole Vision - AI Road Damage Detection/dataset-mix\"\n",
    "    output_root = \"D:/Pothole Vision - AI Road Damage Detection/prepared-datasets/cornernet\"\n",
    "    convert_to_cornernet(dataset_root, output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.136 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.135  Python-3.10.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m-D40, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 8.71.1 MB/s, size: 60.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Pothole Vision - AI Road Damage Detection\\prepared-datasets\\yolov8\\train\\labels.cache... 2951 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2951/2951 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 8.83.2 MB/s, size: 70.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pothole Vision - AI Road Damage Detection\\prepared-datasets\\yolov8\\val\\labels.cache... 723 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1md:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20       3.9G      2.356      2.761      1.931         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [10:27<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:31<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.232      0.164      0.108     0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      3.94G      2.415      2.626      2.012         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [10:12<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:15<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.282      0.221      0.167     0.0579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      3.94G      2.378      2.567      1.966         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [09:11<00:00,  1.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:47<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.347      0.222       0.18     0.0666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      4.07G      2.312      2.473      1.904         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [02:51<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:28<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.339      0.262      0.227     0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      4.07G      2.242       2.37      1.851         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [04:07<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:07<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.382      0.266      0.241     0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      4.06G      2.192      2.301      1.827         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:25<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:53<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.466      0.288       0.28      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      3.94G       2.17      2.249      1.818         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [06:53<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:31<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.401      0.299       0.27      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      4.06G      2.129      2.184      1.781         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [04:13<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:33<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.489      0.319      0.343      0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      4.06G      2.097      2.143      1.765         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:36<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:34<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.448      0.353      0.348      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      4.06G      2.095      2.098      1.756         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:41<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:43<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.475      0.366      0.372      0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      3.96G      2.074      2.035      1.802         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:17<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:44<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.457      0.355       0.36      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      4.07G      2.039      2.017       1.79          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:06<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:35<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.476      0.394      0.393      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      4.05G      2.008      1.957      1.762         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [04:11<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:13<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.539      0.374      0.407      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      4.07G      1.991      1.907      1.753          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [05:25<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:08<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.531      0.395      0.415      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      4.07G      1.977      1.891      1.741         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [05:32<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:57<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.486      0.444      0.435      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      4.05G      1.959      1.839      1.725          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [05:25<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:48<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.531      0.436       0.45      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      4.07G      1.933       1.78      1.708         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [04:52<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:54<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.553       0.45      0.451      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      4.04G      1.905      1.742      1.688          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [07:42<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:07<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.554      0.444      0.471      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      3.98G      1.895      1.694      1.663          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [06:11<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [01:18<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305       0.59      0.452      0.486      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      4.08G      1.869      1.665      1.659         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [03:47<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:54<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305       0.58       0.46      0.482        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 2.121 hours.\n",
      "Optimizer stripped from d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\\weights\\best.pt...\n",
      "Ultralytics 8.3.135  Python-3.10.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:18<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        723       1305      0.592      0.451      0.486      0.203\n",
      "Speed: 0.3ms preprocess, 21.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1md:\\Pothole Vision - AI Road Damage Detection\\runs\\detect\\yolov8m-D40\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000178990BFF70>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,\n",
       "            0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,\n",
       "            0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,     0.97895,\n",
       "            0.97895,     0.97895,     0.97895,     0.97087,     0.97087,     0.97087,     0.97087,     0.97087,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.95902,     0.95902,     0.95902,     0.95902,     0.95902,     0.95902,     0.95902,       0.952,       0.952,\n",
       "            0.94074,     0.94074,     0.94074,     0.94074,     0.94074,     0.94074,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,      0.9359,     0.93125,     0.93125,     0.93125,\n",
       "            0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.93085,     0.92188,     0.92188,     0.91364,     0.91364,\n",
       "            0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.91364,     0.90708,     0.90708,     0.90708,     0.90351,      0.8961,      0.8927,     0.88655,\n",
       "            0.88655,     0.88477,     0.88477,     0.88477,     0.88353,     0.88353,     0.88353,     0.88353,     0.88095,     0.87938,     0.87938,     0.87938,     0.87938,     0.87692,      0.8764,      0.8764,      0.8764,      0.8764,      0.8764,     0.87407,     0.87234,     0.87234,     0.87234,\n",
       "            0.87234,     0.87234,     0.87234,     0.87234,     0.87234,     0.86713,     0.86598,     0.86598,     0.86598,     0.86149,     0.86149,     0.86149,     0.85197,     0.85197,     0.85197,     0.85065,     0.85065,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,\n",
       "            0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84821,     0.84457,     0.84457,     0.84058,     0.83621,     0.83191,     0.83003,     0.82817,      0.8248,      0.8248,      0.8248,      0.8248,\n",
       "             0.8248,      0.8248,      0.8248,      0.8248,      0.8248,     0.82086,     0.81794,     0.81794,     0.81462,     0.81299,     0.81234,     0.81234,     0.80867,     0.80856,     0.80856,     0.80856,     0.80702,     0.80392,     0.80392,     0.80392,     0.80392,     0.80392,     0.80387,\n",
       "            0.80387,     0.80387,     0.80336,     0.80336,      0.7981,     0.79765,     0.79765,     0.79625,     0.79452,     0.79452,     0.79452,     0.79452,     0.79452,     0.79452,     0.79365,     0.79075,     0.79075,     0.79075,     0.79075,     0.79075,     0.79075,     0.79075,     0.79039,\n",
       "            0.79039,     0.79039,      0.7897,      0.7897,      0.7897,      0.7897,     0.78846,     0.78602,     0.78602,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.77823,     0.77246,     0.77246,     0.77246,     0.77246,     0.77246,     0.77246,     0.77137,     0.77075,\n",
       "            0.76908,     0.76908,     0.76803,     0.76641,     0.76641,     0.76538,      0.7619,      0.7619,     0.76128,     0.76128,     0.76128,     0.76128,      0.7551,     0.75461,     0.75461,     0.75271,     0.75271,     0.75271,     0.75271,     0.75271,     0.75271,     0.75043,     0.75043,\n",
       "            0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.75043,     0.74828,      0.7453,      0.7432,     0.73913,     0.73913,     0.73913,     0.73913,     0.73833,     0.73311,     0.73235,     0.73214,     0.73214,     0.73214,\n",
       "            0.73214,     0.72771,     0.72771,     0.72771,     0.72771,     0.72468,     0.72283,     0.72214,     0.72188,     0.72162,     0.72162,     0.71145,     0.71061,     0.71061,     0.71061,     0.71041,     0.70958,     0.70958,     0.70896,     0.70606,     0.70606,     0.70545,     0.70381,\n",
       "            0.70322,     0.69899,     0.69885,     0.69885,     0.69628,     0.69516,     0.69209,     0.69209,     0.68707,     0.68707,     0.68707,     0.68646,     0.68646,     0.68263,     0.67843,     0.67611,     0.67564,     0.67517,     0.67244,     0.67063,     0.67063,      0.6619,     0.65897,\n",
       "            0.65897,     0.65897,     0.65897,     0.65776,     0.65776,      0.6557,     0.65365,     0.65245,     0.65217,     0.65217,     0.65217,      0.6518,     0.64901,     0.64469,     0.64087,     0.63942,     0.63942,     0.63842,     0.63842,     0.63734,     0.63626,     0.63337,     0.63158,\n",
       "             0.6298,     0.62702,     0.62601,     0.62428,     0.62415,     0.62415,     0.62077,     0.62077,     0.61726,     0.61726,     0.61726,     0.61726,     0.61726,     0.61726,     0.61538,      0.6153,      0.6153,     0.61505,     0.61413,     0.61322,     0.61308,     0.61308,     0.61308,\n",
       "            0.61308,     0.61129,     0.61129,     0.60911,     0.60356,     0.60083,     0.59835,     0.59835,     0.59775,     0.59775,     0.59775,     0.59492,     0.59293,     0.59215,     0.59118,     0.58713,     0.58713,     0.58465,     0.58448,     0.58203,     0.58099,     0.58099,     0.57692,\n",
       "            0.57457,     0.57211,     0.56861,     0.56861,     0.56729,     0.56664,     0.56651,     0.56574,     0.56562,     0.56279,     0.56279,     0.55848,     0.55787,     0.55776,     0.55209,     0.54561,     0.54561,     0.53833,     0.53833,      0.5378,     0.53435,     0.53435,     0.53435,\n",
       "            0.53429,     0.52882,     0.52267,     0.51459,     0.51001,     0.50918,     0.50755,     0.50632,      0.5055,      0.5055,     0.50233,     0.50233,     0.50233,     0.50233,     0.50038,     0.49847,     0.49394,     0.49062,     0.48808,     0.48701,     0.48597,     0.48527,     0.48463,\n",
       "            0.48463,     0.48359,     0.48046,     0.47842,     0.47406,     0.47342,      0.4725,      0.4689,     0.46732,     0.46639,     0.46593,     0.46593,     0.46593,     0.46566,     0.46227,     0.45643,     0.45558,     0.44735,     0.44625,     0.44344,     0.44138,     0.44138,     0.43561,\n",
       "             0.4344,     0.43221,     0.43221,     0.43221,     0.43131,     0.43122,     0.43122,      0.4271,      0.4271,      0.4271,     0.42633,     0.42633,      0.4259,     0.42379,      0.4228,      0.4228,      0.4228,     0.41754,     0.41715,     0.41701,     0.41217,     0.41062,     0.40886,\n",
       "            0.40245,     0.40245,     0.40245,     0.39836,     0.39836,     0.39673,     0.39663,     0.39495,     0.39495,     0.39495,     0.39495,     0.39464,      0.3936,     0.39267,     0.39236,     0.39103,     0.38808,     0.38721,     0.38721,     0.38513,     0.38202,     0.37809,     0.37606,\n",
       "            0.37469,     0.37463,     0.36816,     0.35863,     0.35724,     0.35721,     0.35647,     0.35494,     0.35164,     0.35145,      0.3452,      0.3452,     0.34058,     0.33713,     0.33669,     0.33609,     0.33434,     0.33219,      0.3312,     0.33007,     0.32897,     0.32897,     0.32802,\n",
       "            0.32802,     0.32722,     0.32722,     0.32696,     0.32696,      0.3267,     0.32564,     0.32513,     0.32513,     0.32513,     0.32018,     0.31981,     0.31829,     0.31671,     0.31671,      0.3156,     0.31369,     0.31369,      0.3136,     0.31337,     0.30946,     0.30925,     0.30857,\n",
       "            0.30723,     0.30427,     0.30396,     0.30391,      0.3027,     0.30132,     0.29818,     0.29422,     0.29422,     0.29422,     0.29422,     0.29198,     0.29192,     0.29016,      0.2896,     0.28854,     0.28488,      0.2843,      0.2843,     0.28373,     0.28263,     0.28004,     0.27972,\n",
       "            0.27716,     0.27576,      0.2665,     0.26281,     0.26038,     0.25595,     0.25549,      0.2551,     0.25494,     0.25439,     0.25348,      0.2534,     0.25333,     0.25235,     0.25213,     0.24884,     0.24849,     0.24835,     0.24693,     0.24582,     0.24471,     0.24349,     0.24324,\n",
       "            0.24324,     0.24237,      0.2419,     0.23974,     0.23722,     0.23691,      0.2341,     0.23387,     0.22939,     0.22848,       0.227,       0.227,      0.2257,     0.22365,     0.22261,     0.22186,     0.21818,     0.21794,     0.21792,     0.21599,     0.21561,     0.21538,     0.21396,\n",
       "            0.21274,      0.2101,     0.20748,      0.2041,     0.20327,     0.20178,     0.19956,     0.19908,     0.19843,     0.19809,     0.19797,     0.19628,     0.19615,     0.19537,      0.1937,      0.1937,     0.19298,      0.1913,       0.191,     0.18915,     0.18839,      0.1876,     0.18624,\n",
       "            0.18577,     0.18556,     0.18346,     0.18346,     0.18192,     0.18192,     0.18015,      0.1791,     0.17868,     0.17671,     0.17481,     0.17345,     0.17293,     0.16871,     0.16847,      0.1679,     0.16772,     0.16746,     0.16589,     0.16514,     0.16503,     0.16158,     0.15969,\n",
       "            0.15919,     0.15826,     0.15822,     0.15496,     0.15479,     0.15358,     0.15121,     0.15073,      0.1496,      0.1492,     0.14635,     0.14219,     0.14188,     0.14166,     0.14154,     0.14073,     0.14073,     0.14071,     0.14035,     0.13874,     0.13772,     0.13772,     0.13703,\n",
       "            0.13614,     0.13614,     0.13327,     0.13321,     0.13172,     0.13016,      0.1292,     0.12682,     0.12597,     0.12471,     0.11787,     0.11777,     0.11396,     0.11384,     0.11384,     0.11174,     0.11088,     0.10726,      0.1058,     0.10459,     0.10387,      0.1036,     0.10301,\n",
       "            0.10294,     0.10187,     0.10127,     0.10025,    0.099217,    0.097693,    0.097363,    0.097044,    0.095982,     0.09544,    0.095348,    0.094924,    0.093287,    0.092801,     0.09159,    0.090201,    0.090178,    0.090101,    0.089379,    0.087725,    0.087319,    0.086416,    0.085545,\n",
       "           0.085438,    0.085057,     0.08336,    0.081312,    0.081202,      0.0796,    0.079398,    0.079398,    0.078531,    0.077376,    0.076834,    0.076564,    0.076058,    0.075719,    0.074244,    0.073119,    0.072919,    0.072382,    0.071805,    0.071009,    0.070856,     0.06758,    0.066815,\n",
       "            0.06634,    0.065258,    0.065245,    0.065245,    0.062278,    0.060524,    0.060293,    0.060293,    0.059457,    0.058525,    0.058269,     0.05814,     0.05608,    0.054975,    0.054967,      0.0535,     0.05226,    0.051722,    0.049977,    0.048398,    0.046529,    0.045625,    0.045205,\n",
       "           0.045157,    0.045141,    0.044054,    0.043048,    0.043048,    0.041313,    0.041313,     0.04065,    0.040277,    0.040277,    0.040131,    0.039849,    0.039243,     0.03851,    0.037776,    0.037099,    0.037096,     0.03599,    0.035028,    0.034946,    0.034711,    0.034089,    0.033193,\n",
       "           0.032588,     0.03209,    0.031462,    0.030703,    0.029214,    0.027842,    0.026436,    0.026198,    0.024156,    0.023644,    0.023556,    0.022884,    0.022884,    0.022611,    0.021961,    0.021237,    0.020391,    0.020167,    0.018994,    0.018379,    0.018284,    0.016694,    0.016534,\n",
       "           0.016373,    0.016213,    0.016052,    0.015892,    0.015731,    0.015571,     0.01541,     0.01525,    0.015089,    0.014929,    0.014768,    0.014608,    0.014447,    0.014287,    0.014126,    0.013966,    0.013805,    0.013645,    0.013484,    0.013323,    0.013163,    0.013002,    0.012842,\n",
       "           0.012681,    0.012521,     0.01236,      0.0122,    0.012039,    0.011879,    0.011718,    0.011558,    0.011397,    0.011237,    0.011076,    0.010916,    0.010755,    0.010595,    0.010434,    0.010274,    0.010113,   0.0099525,   0.0097919,   0.0096314,   0.0094709,   0.0093104,   0.0091498,\n",
       "          0.0089893,   0.0088288,   0.0086683,   0.0085078,   0.0083472,   0.0081867,   0.0080262,   0.0078657,   0.0077051,   0.0075446,   0.0073841,   0.0072236,    0.007063,   0.0069025,    0.006742,   0.0065815,   0.0064209,   0.0062604,   0.0060999,   0.0059394,   0.0057789,   0.0056183,   0.0054578,\n",
       "          0.0052973,   0.0051368,   0.0049762,   0.0048157,   0.0046552,   0.0044947,   0.0043341,   0.0041736,   0.0040131,   0.0038526,    0.003692,   0.0035315,    0.003371,   0.0032105,   0.0030499,   0.0028894,   0.0027289,   0.0025684,   0.0024079,   0.0022473,   0.0020868,   0.0019263,   0.0017658,\n",
       "          0.0016052,   0.0014447,   0.0012842,   0.0011237,  0.00096314,  0.00080262,  0.00064209,  0.00048157,  0.00032105,  0.00016052,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.032812,    0.032812,    0.048803,     0.06295,    0.075091,    0.086318,    0.097404,     0.10753,     0.11717,     0.12634,     0.13507,     0.14313,     0.15131,     0.15861,     0.16614,     0.17272,     0.17943,     0.18597,     0.19299,     0.19905,     0.20603,     0.21292,     0.21934,\n",
       "            0.22516,     0.23072,      0.2354,     0.23881,     0.24513,     0.25023,     0.25497,     0.25999,     0.26448,     0.27043,     0.27427,      0.2791,     0.28385,     0.28801,     0.29135,     0.29553,      0.2992,     0.30356,     0.30677,     0.30991,     0.31341,     0.31655,     0.32069,\n",
       "            0.32465,     0.32778,     0.33075,     0.33459,     0.33855,     0.34076,     0.34282,     0.34681,      0.3488,     0.35184,      0.3553,     0.35668,     0.35909,     0.36177,     0.36462,      0.3664,     0.36863,     0.37245,     0.37554,     0.37773,     0.38108,     0.38466,      0.3874,\n",
       "            0.38917,     0.39232,     0.39312,     0.39477,      0.3979,      0.3993,      0.4006,     0.40233,     0.40574,     0.40749,     0.40845,     0.41114,     0.41228,     0.41364,     0.41547,     0.41692,     0.41829,      0.4196,     0.42177,     0.42324,     0.42398,     0.42396,     0.42324,\n",
       "            0.42542,     0.42751,     0.42944,     0.43123,     0.43283,     0.43413,     0.43626,      0.4385,     0.43984,     0.44201,     0.44243,     0.44454,     0.44699,     0.44936,      0.4506,     0.45338,     0.45376,     0.45497,     0.45721,     0.45936,      0.4612,     0.46107,     0.46313,\n",
       "            0.46381,     0.46394,     0.46281,     0.46405,     0.46407,     0.46588,     0.46718,     0.46768,     0.47089,     0.47191,     0.47423,     0.47552,     0.47579,      0.4763,     0.47628,     0.47449,      0.4761,     0.47692,     0.47666,     0.47696,     0.47618,     0.47703,     0.47816,\n",
       "            0.48042,     0.48097,     0.48212,     0.48218,     0.48283,     0.48367,     0.48471,     0.48678,     0.48834,     0.48939,     0.49104,     0.48967,     0.49035,     0.49126,     0.49195,     0.49155,     0.49152,     0.49281,     0.49296,     0.49418,     0.49439,     0.49515,     0.49468,\n",
       "            0.49427,     0.49463,     0.49521,     0.49664,     0.49699,     0.49829,     0.49864,     0.49899,     0.49794,     0.49834,      0.4981,     0.49878,     0.49838,     0.49893,     0.49929,     0.49962,     0.49989,     0.50112,     0.50192,     0.50342,     0.50335,      0.5045,      0.5058,\n",
       "            0.50581,     0.50698,     0.50613,      0.5069,     0.50663,     0.50658,     0.50697,     0.50752,     0.50809,     0.51063,      0.5111,     0.51197,     0.51144,     0.51139,     0.51244,     0.51222,     0.51224,     0.51156,     0.51092,     0.51068,      0.5101,     0.51028,     0.51116,\n",
       "            0.51074,     0.51112,     0.51187,     0.51097,     0.51173,     0.51192,     0.51078,       0.512,     0.51185,     0.51158,     0.51117,     0.51142,     0.51148,     0.51096,     0.51051,     0.50932,     0.50944,      0.5102,     0.51036,     0.51023,     0.51125,     0.51093,     0.51107,\n",
       "             0.5094,      0.5089,     0.50806,     0.50702,     0.50602,     0.50521,     0.50532,     0.50516,     0.50423,     0.50217,     0.50187,     0.50199,     0.50201,     0.50107,     0.50042,     0.50027,     0.50012,     0.49906,     0.49985,     0.49944,     0.49999,     0.49986,     0.49948,\n",
       "            0.49951,     0.49919,     0.49973,     0.49935,      0.4992,     0.49794,     0.49697,     0.49711,     0.49672,     0.49696,     0.49658,      0.4966,     0.49775,     0.49729,     0.49785,     0.49534,     0.49455,     0.49396,     0.49447,     0.49348,     0.49295,     0.49174,     0.49026,\n",
       "            0.49026,     0.49027,     0.49057,     0.49111,     0.49168,     0.49069,     0.49122,     0.49072,      0.4904,     0.49011,     0.48929,     0.48908,      0.4896,     0.49017,     0.48918,      0.4895,     0.48983,     0.48853,     0.48593,     0.48643,     0.48657,     0.48657,     0.48612,\n",
       "            0.48531,     0.48491,     0.48493,      0.4834,     0.48292,     0.48246,     0.48247,      0.4803,      0.4805,     0.47822,     0.47842,     0.47534,     0.47548,     0.47518,     0.47544,     0.47598,     0.47627,     0.47311,     0.47263,     0.47289,     0.47107,      0.4694,     0.46821,\n",
       "            0.46924,     0.46809,     0.46539,     0.46416,     0.46446,     0.46499,     0.46452,     0.46293,     0.46153,      0.4608,     0.46156,     0.46123,     0.46076,     0.46045,     0.46013,     0.45889,     0.45746,     0.45565,     0.45452,      0.4543,      0.4526,      0.4506,     0.45035,\n",
       "            0.44986,     0.44888,     0.44564,     0.44293,     0.44318,     0.44348,     0.44285,        0.44,     0.44026,     0.44038,     0.44058,     0.44038,     0.43866,     0.43691,     0.43546,     0.43554,     0.43371,     0.43326,     0.43323,     0.43332,     0.43341,     0.43139,     0.43044,\n",
       "            0.43069,     0.42898,     0.42747,     0.42658,     0.42513,     0.42526,     0.42391,     0.42284,     0.42258,      0.4225,     0.42298,     0.42234,     0.42281,      0.4208,     0.41989,     0.41833,     0.41806,     0.41802,      0.4175,     0.41606,     0.41495,     0.41157,     0.40885,\n",
       "            0.40839,     0.40797,     0.40811,     0.40715,     0.40465,     0.40259,     0.40051,     0.40063,      0.4008,     0.39938,     0.39895,     0.39848,     0.39416,     0.39321,     0.39188,     0.39142,     0.39081,     0.38931,     0.38915,     0.38899,     0.38883,     0.38867,     0.38851,\n",
       "            0.38897,     0.38661,     0.38642,     0.38585,     0.38395,     0.38289,     0.38129,     0.37842,     0.37759,     0.37712,     0.37614,     0.37516,     0.37418,     0.37342,     0.37269,     0.37189,     0.37025,     0.36951,      0.3686,     0.36827,     0.36794,     0.36785,     0.36753,\n",
       "            0.36578,     0.36563,     0.36498,     0.36489,     0.36439,     0.36378,     0.36328,     0.35942,     0.35545,     0.35554,     0.35477,     0.35499,     0.35402,     0.35343,     0.35167,     0.35206,     0.35155,     0.35145,     0.35087,     0.34956,     0.34967,     0.34948,     0.34724,\n",
       "            0.34683,     0.34506,     0.34454,     0.34373,     0.34168,     0.34142,      0.3398,     0.33774,     0.33568,     0.33463,     0.33417,     0.33365,     0.33271,     0.32914,     0.32879,     0.32843,     0.32745,     0.32536,      0.3243,     0.32431,     0.32436,     0.32441,     0.32467,\n",
       "            0.32477,     0.32176,      0.3218,     0.32073,     0.31861,     0.31778,     0.31788,     0.31821,      0.3172,     0.31546,      0.3114,      0.3105,     0.30995,     0.30966,     0.30972,     0.30979,     0.30992,     0.30947,     0.30731,     0.30545,      0.3049,     0.30402,     0.30185,\n",
       "            0.30158,     0.29983,     0.29891,     0.29759,     0.29769,     0.29686,     0.29466,     0.29245,     0.29106,     0.29069,     0.29031,     0.28936,     0.28801,     0.28773,     0.28745,     0.28714,     0.28513,     0.28456,     0.28302,     0.28077,     0.27973,     0.27916,     0.27847,\n",
       "             0.2764,     0.27526,     0.27427,      0.2737,      0.2733,     0.27273,     0.27015,     0.27021,     0.27027,     0.26996,     0.26898,     0.26862,     0.26871,     0.26812,     0.26747,     0.26689,     0.26594,     0.26516,     0.26457,     0.26359,     0.26276,     0.26045,     0.25874,\n",
       "            0.25835,     0.25796,      0.2569,     0.25343,      0.2526,     0.25048,      0.2497,      0.2494,     0.24911,     0.24881,     0.24719,      0.2466,     0.24522,     0.24498,     0.24474,      0.2445,     0.24426,     0.24281,     0.24251,     0.24221,     0.24191,     0.23971,     0.23927,\n",
       "            0.23897,     0.23867,     0.23837,      0.2385,     0.23617,     0.23638,     0.23644,     0.23581,     0.23495,     0.23434,     0.23421,     0.23432,      0.2344,     0.23296,     0.23256,     0.23215,     0.23112,     0.23039,     0.22978,     0.22627,     0.22385,     0.22101,     0.22066,\n",
       "            0.22031,     0.21833,     0.21759,     0.21734,      0.2171,     0.21685,      0.2166,     0.21612,      0.2155,     0.21048,     0.21047,     0.20984,     0.20922,      0.2086,     0.20778,     0.20674,     0.20611,     0.20402,     0.20339,     0.20226,     0.20036,     0.19973,     0.19739,\n",
       "            0.19675,     0.19484,     0.19357,      0.1911,     0.19025,     0.18663,     0.18327,     0.18262,     0.18152,     0.18023,     0.17767,     0.17472,     0.16832,     0.16701,     0.16625,     0.16637,     0.16606,     0.16518,     0.16398,     0.16333,     0.16138,     0.16085,     0.16032,\n",
       "            0.15971,     0.15905,     0.15796,     0.15708,     0.15641,     0.15465,     0.15427,     0.15389,     0.15322,     0.15235,     0.15243,     0.14866,     0.14469,     0.14334,      0.1429,     0.14251,     0.14213,     0.14197,     0.14201,     0.14202,     0.14172,     0.14142,     0.14112,\n",
       "            0.14082,     0.13902,     0.13848,     0.13658,     0.13589,       0.135,     0.13278,     0.13285,     0.13266,     0.13243,      0.1322,     0.13197,     0.13175,     0.13152,     0.13112,     0.13073,     0.13034,     0.12995,     0.12956,     0.12917,     0.12738,     0.12669,      0.1246,\n",
       "            0.12368,     0.12317,     0.12277,     0.12238,      0.1218,     0.12087,     0.11925,     0.11905,     0.11885,     0.11865,     0.11845,     0.11826,     0.11801,     0.11708,     0.11344,     0.11254,     0.11184,     0.11118,     0.11072,     0.11025,     0.10972,     0.10902,     0.10825,\n",
       "            0.10731,     0.10363,     0.10156,     0.10128,       0.101,     0.10071,     0.10043,    0.099814,    0.097508,    0.097103,    0.096697,    0.096291,    0.094157,    0.093207,    0.092256,    0.091637,    0.091161,    0.090685,    0.088812,    0.088334,    0.087857,    0.082967,    0.082247,\n",
       "            0.08131,    0.078936,    0.077971,    0.076058,    0.075574,     0.07509,    0.074605,    0.074121,    0.073636,    0.073151,    0.072665,    0.066556,     0.06623,    0.065904,    0.065577,    0.065251,    0.064403,    0.063669,    0.063423,    0.063178,    0.062933,    0.062687,    0.062442,\n",
       "           0.060792,    0.060619,    0.060445,    0.060271,    0.060098,    0.059924,     0.05975,    0.059576,    0.059249,    0.058263,    0.057276,    0.054841,     0.05385,    0.051724,    0.051128,    0.049193,    0.048921,    0.048649,    0.048378,    0.048106,    0.047834,     0.04684,    0.045842,\n",
       "           0.044869,    0.044269,    0.043669,    0.043209,    0.042834,    0.042458,    0.042082,     0.03978,    0.035825,    0.034815,    0.034127,    0.033521,    0.032913,    0.032306,    0.031698,    0.030715,    0.029467,    0.028385,    0.027774,    0.027163,    0.026552,    0.025941,    0.023974,\n",
       "           0.023591,    0.023208,    0.022824,    0.022279,    0.021665,    0.020807,    0.019416,    0.018389,    0.016937,     0.01618,    0.015562,    0.015016,    0.014574,    0.014132,     0.01369,    0.012168,    0.011725,    0.011281,    0.010838,    0.010666,     0.01056,   0.0097828,   0.0091404,\n",
       "          0.0090727,    0.009005,   0.0089373,   0.0088696,   0.0088019,   0.0087342,   0.0086665,   0.0085988,   0.0085311,   0.0084634,   0.0083957,   0.0083279,   0.0082602,   0.0081925,   0.0081247,    0.008057,   0.0079892,   0.0079214,   0.0078537,   0.0077859,   0.0077181,   0.0076504,    0.007466,\n",
       "          0.0072432,   0.0070204,   0.0067975,   0.0065746,   0.0063517,   0.0061286,   0.0059193,   0.0057111,   0.0055028,   0.0052944,   0.0050861,   0.0048777,   0.0046692,   0.0045239,   0.0044197,   0.0043154,   0.0042111,   0.0041068,   0.0040025,   0.0038982,   0.0037939,   0.0036895,   0.0035852,\n",
       "          0.0034808,   0.0033765,   0.0032721,   0.0031677,   0.0030633,   0.0029081,   0.0027515,   0.0025948,   0.0024381,   0.0022814,   0.0021246,   0.0019678,   0.0018111,   0.0016542,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016712,    0.016712,    0.025096,     0.03265,    0.039252,    0.045466,     0.05168,    0.057442,    0.063019,      0.0684,    0.073588,    0.078466,    0.083472,    0.088016,    0.092744,    0.096969,     0.10129,      0.1056,     0.11019,     0.11426,     0.11894,     0.12356,     0.12799,\n",
       "            0.13206,     0.13602,     0.13942,     0.14212,     0.14665,     0.15041,     0.15398,     0.15773,     0.16126,     0.16582,     0.16905,     0.17282,     0.17656,     0.17999,     0.18281,     0.18642,     0.18962,     0.19331,     0.19634,     0.19923,     0.20233,     0.20515,     0.20871,\n",
       "            0.21215,     0.21498,     0.21815,     0.22167,     0.22541,     0.22764,     0.22974,     0.23335,     0.23542,      0.2384,     0.24179,     0.24368,     0.24614,     0.24932,     0.25226,     0.25466,     0.25742,     0.26128,     0.26446,      0.2669,     0.27025,     0.27388,      0.2768,\n",
       "             0.2789,     0.28244,     0.28402,     0.28605,     0.28951,     0.29177,      0.2939,     0.29589,     0.29977,     0.30204,     0.30364,       0.307,     0.30884,     0.31095,     0.31353,     0.31587,     0.31827,     0.32022,     0.32276,     0.32501,     0.32668,     0.32802,     0.32855,\n",
       "            0.33166,     0.33469,     0.33807,     0.34042,      0.3428,     0.34496,     0.34794,     0.35079,     0.35308,     0.35616,     0.35787,     0.36093,     0.36419,     0.36734,     0.36963,     0.37338,     0.37446,     0.37684,     0.38028,      0.3836,     0.38687,     0.38811,     0.39141,\n",
       "            0.39311,      0.3948,     0.39506,     0.39842,     0.39886,     0.40234,     0.40468,     0.40586,     0.41157,       0.414,     0.41893,      0.4214,     0.42321,     0.42496,     0.42608,     0.42588,     0.42847,     0.43081,     0.43108,     0.43207,      0.4321,     0.43454,     0.43694,\n",
       "            0.44126,     0.44328,     0.44607,     0.44644,     0.44812,     0.45014,     0.45194,     0.45613,     0.45948,     0.46194,      0.4656,     0.46613,     0.46927,     0.47094,     0.47239,     0.47344,      0.4747,     0.47712,     0.47806,     0.48043,     0.48145,     0.48426,     0.48622,\n",
       "            0.48686,     0.48828,     0.49045,      0.4937,     0.49513,     0.49849,     0.49919,     0.50067,     0.50133,     0.50408,     0.50623,     0.50914,     0.50908,     0.51108,     0.51183,     0.51336,      0.5148,     0.51741,     0.51911,     0.52233,     0.52307,     0.52558,     0.52869,\n",
       "            0.53024,     0.53283,     0.53376,     0.53738,     0.53774,     0.53957,     0.54144,     0.54269,     0.54601,     0.55204,     0.55405,      0.5576,     0.55912,     0.56006,     0.56274,     0.56426,     0.56543,     0.56601,     0.56636,     0.56856,     0.56928,     0.57206,     0.57428,\n",
       "            0.57443,     0.57658,      0.5785,     0.57986,     0.58183,     0.58611,     0.58659,     0.59018,     0.59085,      0.5917,     0.59178,     0.59392,      0.5968,      0.5972,     0.59826,     0.59914,      0.6009,     0.60302,     0.60345,     0.60454,      0.6074,     0.60941,     0.61279,\n",
       "            0.61248,     0.61217,     0.61316,     0.61519,     0.61456,     0.61568,     0.61601,     0.61723,     0.61665,     0.61589,     0.61855,     0.62056,     0.62411,     0.62353,     0.62415,     0.62541,     0.62669,     0.62682,     0.62931,     0.62945,     0.63158,     0.63291,     0.63305,\n",
       "            0.63427,     0.63408,     0.63614,     0.63674,      0.6381,     0.63758,     0.63885,     0.64062,     0.64124,     0.64205,     0.64268,     0.64434,     0.64894,     0.64902,     0.65092,     0.65078,     0.65231,     0.65377,     0.65774,     0.65715,     0.65862,     0.65818,     0.65799,\n",
       "            0.65979,     0.66205,     0.66314,     0.66738,     0.66946,     0.66986,     0.67242,     0.67212,     0.67391,      0.6748,     0.67678,     0.67839,      0.6804,      0.6826,     0.68364,     0.68493,     0.68622,     0.68567,     0.68589,     0.68789,     0.68845,     0.69103,     0.69167,\n",
       "            0.69459,     0.69479,     0.69755,     0.69937,      0.7029,     0.70375,     0.70523,      0.7049,     0.70675,     0.70849,     0.71027,     0.71068,     0.71132,     0.71611,     0.71728,     0.71978,     0.72107,     0.72245,     0.72344,     0.72464,     0.72674,     0.72581,      0.7257,\n",
       "            0.73065,     0.73134,     0.73307,     0.73366,     0.73516,     0.73781,     0.73802,     0.73826,     0.73861,     0.73853,     0.74245,     0.74294,      0.7459,     0.74813,     0.75031,     0.74977,     0.74901,     0.74804,     0.74804,     0.74969,     0.74975,      0.7489,     0.74997,\n",
       "            0.74971,     0.75162,      0.7511,     0.75052,     0.75193,     0.75367,      0.7546,     0.75571,     0.75725,     0.75797,     0.75916,     0.76098,     0.76007,     0.76038,       0.761,      0.7664,     0.76544,     0.76521,     0.76672,     0.76728,     0.76783,     0.76833,      0.7691,\n",
       "            0.77069,     0.76985,     0.77188,     0.77141,      0.7709,     0.77181,     0.77144,     0.77178,     0.77363,     0.77491,     0.77817,     0.77936,      0.7826,     0.78158,     0.78111,     0.78182,     0.78375,     0.78471,     0.78444,     0.78525,     0.78938,     0.78925,     0.78947,\n",
       "            0.78923,     0.78911,     0.79071,     0.79022,     0.78957,     0.78952,     0.79046,     0.79137,     0.79273,     0.79286,     0.79434,     0.79409,     0.79358,     0.79309,     0.79743,      0.7974,     0.79708,     0.79808,       0.798,     0.79792,     0.79784,     0.79775,     0.79767,\n",
       "            0.80236,     0.80211,     0.80321,     0.80355,     0.80258,      0.8034,     0.80307,     0.80159,     0.80392,     0.80852,     0.80803,     0.80753,     0.80703,       0.807,     0.80862,     0.81174,     0.81143,     0.81311,     0.81409,     0.81392,     0.81375,     0.81475,     0.81762,\n",
       "            0.81882,     0.82022,      0.8205,     0.82205,     0.82443,     0.82413,     0.82389,     0.82199,        0.82,     0.82202,     0.82388,     0.82624,     0.82585,     0.83002,     0.83152,     0.83619,     0.83595,     0.84055,     0.84028,     0.84016,     0.84141,     0.84436,     0.84692,\n",
       "            0.84798,     0.84718,     0.84695,     0.84658,     0.84564,     0.84709,     0.84725,      0.8463,     0.84534,     0.84485,     0.84717,     0.84693,     0.84649,      0.8448,     0.84463,     0.84446,     0.84399,     0.84298,     0.84246,     0.84311,     0.84381,     0.84451,     0.84798,\n",
       "            0.84939,     0.84949,     0.85191,     0.85141,     0.85041,      0.8503,     0.85176,     0.85646,     0.86088,     0.86584,     0.86698,     0.86658,     0.86634,     0.86662,     0.86766,     0.86871,     0.87076,     0.87211,     0.87118,     0.87037,     0.87013,     0.86975,     0.86879,\n",
       "            0.87072,       0.871,     0.87374,     0.87434,     0.87602,     0.87604,     0.87509,     0.87412,     0.87679,     0.87662,     0.87646,     0.87917,     0.87879,     0.87867,     0.87855,     0.87841,     0.88094,     0.88069,     0.88348,     0.88253,     0.88207,     0.88183,     0.88153,\n",
       "            0.88418,     0.88369,     0.88326,     0.88301,     0.88647,     0.88623,      0.8856,     0.88689,     0.88818,     0.89249,     0.89588,     0.90058,      0.9026,     0.90327,     0.90696,     0.90675,      0.9064,     0.90611,      0.9059,     0.90553,     0.91335,     0.91254,     0.91193,\n",
       "            0.91179,     0.91165,     0.91127,        0.91,     0.90969,      0.9089,      0.9086,     0.90849,     0.90838,     0.90826,     0.90764,     0.90741,     0.91128,     0.91119,      0.9111,     0.91101,     0.91092,     0.91037,     0.91025,     0.91014,     0.91002,     0.90916,     0.90899,\n",
       "            0.90887,     0.90875,     0.90864,      0.9131,     0.91238,     0.91904,       0.921,     0.92164,     0.92134,     0.92113,     0.92417,     0.92756,     0.93009,     0.93039,     0.93026,     0.93014,     0.92981,     0.92957,     0.92938,     0.92823,     0.92742,     0.92644,     0.92632,\n",
       "             0.9262,     0.92551,     0.92524,     0.92515,     0.92507,     0.92498,     0.92489,     0.92472,     0.92449,     0.92367,      0.9281,     0.92788,     0.92765,     0.92743,     0.92713,     0.92675,     0.92652,     0.92575,     0.93027,     0.93084,     0.93017,     0.92994,     0.93506,\n",
       "            0.93484,     0.93418,     0.93373,     0.93285,     0.93254,     0.93119,      0.9299,     0.92965,     0.92921,     0.92869,     0.92765,     0.94016,     0.93782,     0.93732,     0.93991,     0.94759,     0.95189,     0.95162,     0.95895,     0.95884,     0.95833,     0.95818,     0.95804,\n",
       "            0.95787,     0.95769,     0.95739,     0.95714,     0.95695,     0.95644,     0.95633,     0.95622,     0.95602,     0.95769,     0.96353,     0.96334,     0.96229,     0.96193,      0.9618,      0.9617,     0.96159,     0.96356,     0.96739,     0.97087,      0.9708,     0.97074,     0.97067,\n",
       "            0.97061,     0.97021,     0.97009,     0.96966,      0.9695,     0.96929,     0.97107,     0.97804,     0.97891,     0.97888,     0.97884,      0.9788,     0.97876,     0.97872,     0.97866,     0.97859,     0.97852,     0.97845,     0.97838,     0.97832,       0.978,     0.97787,     0.97749,\n",
       "            0.97731,     0.97721,     0.97714,     0.97706,     0.97695,     0.97676,     0.97643,     0.97639,     0.97635,     0.97631,     0.97627,     0.97623,     0.97618,     0.97598,     0.97518,     0.97498,     0.97482,     0.97466,     0.97455,     0.97444,     0.97431,     0.97414,     0.97395,\n",
       "            0.97372,     0.97276,     0.97219,     0.97211,     0.97203,     0.97195,     0.97187,     0.97169,     0.97101,     0.97088,     0.97076,     0.97063,     0.96996,     0.96964,     0.96933,     0.96912,     0.96895,     0.96879,     0.96812,     0.96794,     0.96777,     0.96585,     0.96555,\n",
       "            0.96515,     0.96409,     0.96365,     0.96273,     0.96249,     0.96225,     0.96201,     0.96176,     0.96151,     0.96125,     0.96099,     0.97824,     0.97813,     0.97802,     0.97791,      0.9778,      0.9775,     0.97724,     0.97715,     0.97706,     0.97697,     0.97688,     0.97679,\n",
       "            0.97616,     0.97609,     0.97602,     0.97595,     0.97588,     0.97581,     0.97574,     0.97567,     0.97553,     0.97511,     0.97468,     0.97356,     0.97307,     0.97196,     0.97164,     0.97053,     0.97036,      0.9702,     0.97003,     0.96986,      0.9697,     0.96905,     0.96838,\n",
       "            0.96771,     0.96727,     0.96683,     0.96648,     0.96619,     0.96589,      0.9656,     0.96363,      0.9597,     0.95856,     0.95774,       0.957,     0.95623,     0.95542,     0.95461,     0.95318,     0.95126,     0.94948,      0.9484,     0.94732,     0.94612,     0.94492,     0.94061,\n",
       "            0.93966,     0.93872,     0.93778,      0.9363,     0.93459,     0.93205,     0.92749,     0.92374,     0.91766,     0.91403,     0.91092,       0.908,     0.90534,     0.90267,     0.90001,     0.88881,     0.88474,     0.88067,      0.8766,     0.92672,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.89579,     0.89579,     0.88199,     0.87433,      0.8636,     0.85057,     0.84521,     0.83985,     0.83218,     0.82605,     0.82069,     0.81379,     0.80766,     0.80153,     0.79617,     0.78927,     0.78467,     0.77854,     0.77625,     0.77165,     0.76935,     0.76935,     0.76628,\n",
       "            0.76322,     0.75939,     0.75556,     0.74713,     0.74636,     0.74406,       0.741,     0.73946,     0.73487,     0.73257,     0.72644,      0.7249,     0.72337,     0.72031,     0.71724,     0.71264,     0.70881,     0.70651,     0.70115,     0.69732,     0.69502,     0.69272,     0.69195,\n",
       "            0.69119,     0.68966,     0.68352,     0.68199,     0.67969,     0.67739,      0.6751,      0.6751,      0.6728,     0.67126,     0.66973,     0.66513,      0.6636,       0.659,     0.65747,     0.65287,     0.64904,     0.64828,     0.64751,     0.64598,     0.64598,     0.64598,     0.64521,\n",
       "            0.64368,     0.64215,     0.63831,     0.63678,     0.63602,     0.63233,     0.62896,     0.62835,     0.62759,     0.62605,     0.62375,     0.62222,     0.61992,     0.61762,     0.61562,     0.61303,     0.60996,     0.60843,     0.60843,     0.60658,     0.60383,     0.59922,     0.59464,\n",
       "             0.5931,     0.59157,     0.58851,     0.58811,     0.58697,     0.58544,     0.58467,     0.58467,     0.58314,     0.58238,     0.57931,     0.57854,     0.57854,     0.57854,     0.57701,     0.57701,     0.57567,     0.57395,     0.57318,     0.57241,     0.57088,     0.56782,     0.56705,\n",
       "            0.56552,     0.56245,     0.55862,     0.55556,     0.55479,     0.55326,     0.55249,     0.55172,     0.55019,     0.54866,     0.54636,     0.54559,      0.5433,     0.54176,     0.53988,     0.53563,     0.53563,      0.5341,     0.53302,     0.53225,     0.53027,     0.52874,     0.52797,\n",
       "             0.5272,     0.52567,     0.52452,     0.52414,     0.52337,     0.52261,     0.52261,     0.52184,     0.52107,     0.52031,     0.51942,     0.51571,     0.51341,     0.51341,     0.51319,     0.51111,     0.50958,     0.50958,     0.50881,     0.50875,     0.50805,     0.50655,     0.50345,\n",
       "            0.50192,     0.50115,     0.50007,     0.49962,     0.49885,     0.49808,     0.49808,     0.49732,     0.49458,     0.49272,     0.49023,     0.48882,     0.48812,     0.48736,     0.48736,     0.48659,     0.48582,     0.48582,     0.48582,     0.48582,     0.48506,     0.48506,     0.48481,\n",
       "            0.48352,     0.48352,     0.48123,     0.47969,     0.47893,     0.47739,     0.47663,     0.47663,      0.4751,       0.475,     0.47433,     0.47325,     0.47126,      0.4705,      0.4704,     0.46897,      0.4682,     0.46667,     0.46537,      0.4635,     0.46207,     0.46054,     0.46054,\n",
       "            0.45977,       0.459,       0.459,      0.4567,      0.4567,     0.45441,     0.45232,     0.45211,     0.45149,     0.45057,     0.44989,     0.44904,     0.44751,     0.44648,     0.44521,     0.44291,     0.44215,     0.44215,     0.44215,     0.44138,     0.44138,     0.43985,     0.43831,\n",
       "            0.43601,     0.43544,     0.43372,     0.43121,     0.43006,     0.42835,     0.42835,     0.42753,     0.42648,      0.4239,     0.42222,     0.42146,     0.41987,     0.41882,     0.41762,     0.41686,     0.41609,     0.41456,     0.41456,     0.41394,     0.41379,     0.41303,     0.41246,\n",
       "            0.41198,     0.41163,     0.41149,     0.41073,     0.40996,     0.40847,     0.40666,     0.40613,     0.40536,     0.40536,      0.4046,     0.40398,      0.4037,     0.40307,     0.40307,     0.39984,     0.39823,     0.39693,     0.39614,     0.39509,     0.39387,     0.39248,     0.39067,\n",
       "            0.39004,     0.38927,     0.38927,     0.38851,     0.38851,     0.38714,     0.38694,     0.38642,     0.38544,     0.38479,     0.38314,     0.38238,     0.38238,     0.38238,     0.38084,     0.38084,     0.38084,     0.37944,     0.37625,     0.37625,     0.37625,     0.37548,     0.37475,\n",
       "            0.37294,     0.37241,     0.37165,     0.36935,     0.36782,     0.36705,     0.36666,     0.36425,     0.36398,     0.36092,     0.36068,     0.35709,     0.35709,     0.35556,     0.35556,     0.35556,     0.35556,     0.35172,     0.35096,     0.35096,     0.34848,     0.34686,     0.34559,\n",
       "            0.34559,     0.34419,     0.34091,     0.33946,     0.33946,     0.33946,     0.33892,     0.33718,     0.33562,     0.33487,     0.33487,     0.33442,     0.33333,     0.33257,      0.3318,     0.33063,     0.32929,      0.3276,     0.32644,     0.32589,     0.32414,     0.32224,     0.32179,\n",
       "            0.32134,     0.31999,      0.3168,     0.31418,     0.31418,     0.31417,     0.31338,     0.31034,     0.31034,     0.31034,     0.31034,     0.30984,     0.30829,     0.30651,     0.30499,     0.30421,     0.30257,     0.30218,     0.30192,     0.30192,     0.30192,     0.29988,     0.29885,\n",
       "            0.29885,     0.29733,     0.29559,      0.2948,     0.29349,     0.29349,     0.29225,     0.29119,     0.29068,     0.29042,     0.29042,     0.28966,     0.28965,      0.2879,     0.28712,     0.28557,     0.28506,     0.28489,     0.28444,       0.283,     0.28145,     0.27836,     0.27586,\n",
       "            0.27547,      0.2751,     0.27503,     0.27422,     0.27203,     0.27018,      0.2682,      0.2682,      0.2682,     0.26691,     0.26637,     0.26597,      0.2622,     0.26141,     0.25977,     0.25937,     0.25886,     0.25744,     0.25731,     0.25718,     0.25705,     0.25692,     0.25679,\n",
       "             0.2567,     0.25469,     0.25441,     0.25388,     0.25233,     0.25134,     0.24999,     0.24767,     0.24674,     0.24591,     0.24513,     0.24434,     0.24356,     0.24291,     0.24215,      0.2412,     0.23985,     0.23908,     0.23823,     0.23797,     0.23771,     0.23755,     0.23704,\n",
       "            0.23549,     0.23525,     0.23469,     0.23448,     0.23388,     0.23341,     0.23301,     0.22999,     0.22691,     0.22682,     0.22605,     0.22605,      0.2253,     0.22451,     0.22299,     0.22297,     0.22257,     0.22217,     0.22172,     0.22069,     0.22069,     0.22034,     0.21839,\n",
       "              0.218,     0.21665,     0.21626,     0.21564,     0.21409,     0.21379,     0.21252,     0.21097,     0.20942,     0.20863,     0.20814,     0.20774,     0.20704,     0.20438,     0.20412,     0.20386,     0.20313,     0.20158,      0.2008,     0.20077,     0.20077,     0.20077,     0.20077,\n",
       "            0.20077,     0.19847,     0.19836,     0.19758,     0.19603,      0.1954,      0.1954,      0.1954,     0.19442,     0.19286,     0.18978,     0.18913,     0.18874,     0.18851,     0.18851,     0.18851,     0.18851,     0.18811,     0.18656,     0.18523,     0.18483,      0.1842,     0.18265,\n",
       "            0.18238,     0.18108,      0.1803,     0.17931,     0.17931,     0.17871,     0.17715,      0.1756,     0.17449,     0.17423,     0.17397,     0.17318,     0.17223,     0.17203,     0.17184,     0.17162,     0.17009,      0.1697,      0.1685,     0.16694,     0.16622,     0.16583,     0.16535,\n",
       "             0.1638,     0.16302,     0.16234,     0.16195,     0.16156,     0.16116,     0.15939,     0.15939,     0.15939,     0.15903,     0.15825,     0.15785,     0.15785,     0.15742,     0.15686,     0.15647,     0.15583,      0.1553,     0.15491,     0.15424,     0.15346,     0.15191,     0.15076,\n",
       "            0.15049,     0.15023,     0.14953,     0.14721,     0.14666,     0.14526,     0.14474,     0.14454,     0.14435,     0.14415,     0.14308,     0.14269,     0.14167,     0.14151,     0.14135,      0.1412,     0.14104,     0.14009,     0.13989,      0.1397,      0.1395,     0.13805,     0.13777,\n",
       "            0.13757,     0.13737,     0.13718,     0.13716,     0.13564,     0.13563,     0.13563,      0.1352,     0.13464,     0.13425,      0.1341,      0.1341,      0.1341,     0.13315,     0.13289,     0.13263,     0.13196,     0.13149,      0.1311,     0.12884,     0.12729,     0.12547,     0.12525,\n",
       "            0.12502,     0.12376,     0.12329,     0.12314,     0.12298,     0.12282,     0.12266,     0.12236,     0.12197,     0.11877,     0.11869,      0.1183,     0.11791,     0.11751,       0.117,     0.11634,     0.11595,     0.11464,     0.11418,     0.11346,     0.11227,     0.11188,     0.11034,\n",
       "            0.10995,     0.10876,     0.10798,     0.10645,     0.10593,      0.1037,     0.10165,     0.10126,     0.10058,    0.099796,    0.098245,     0.09631,    0.092459,    0.091674,    0.091188,    0.091188,    0.090962,    0.090439,    0.089655,    0.089266,     0.08811,    0.087796,    0.087482,\n",
       "            0.08712,    0.086728,     0.08608,    0.085559,    0.085166,    0.084129,    0.083904,     0.08368,    0.083283,    0.082759,    0.082759,    0.080543,    0.078225,     0.07744,    0.077183,    0.076959,    0.076734,    0.076628,    0.076628,    0.076613,    0.076438,    0.076264,    0.076089,\n",
       "           0.075915,    0.074876,    0.074562,    0.073461,    0.073068,    0.072554,    0.071264,    0.071264,     0.07115,     0.07102,    0.070889,    0.070758,    0.070627,    0.070494,     0.07027,    0.070046,    0.069821,    0.069597,    0.069372,    0.069148,    0.068126,    0.067733,    0.066543,\n",
       "           0.066019,    0.065727,    0.065503,    0.065278,    0.064946,    0.064423,    0.063501,    0.063389,    0.063277,    0.063164,    0.063052,     0.06294,    0.062801,    0.062277,    0.060221,    0.059715,    0.059323,    0.058955,    0.058693,    0.058431,    0.058135,    0.057742,    0.057309,\n",
       "           0.056785,    0.054729,     0.05358,    0.053423,    0.053265,    0.053108,    0.052951,    0.052609,    0.051332,    0.051107,    0.050883,    0.050658,     0.04948,    0.048956,    0.048433,    0.048092,    0.047831,    0.047569,    0.046541,    0.046279,    0.046017,    0.043345,    0.042953,\n",
       "           0.042443,    0.041153,    0.040629,    0.039593,    0.039331,    0.039069,    0.038808,    0.038546,    0.038284,    0.038022,     0.03776,     0.03445,    0.034275,    0.034101,    0.033926,    0.033752,    0.033298,    0.032906,    0.032775,    0.032644,    0.032514,    0.032383,    0.032252,\n",
       "           0.031373,    0.031281,    0.031188,    0.031096,    0.031003,    0.030911,    0.030819,    0.030726,    0.030552,    0.030028,    0.029505,    0.028215,    0.027691,    0.026569,    0.026255,    0.025236,    0.025093,     0.02495,    0.024807,    0.024665,    0.024522,       0.024,    0.023477,\n",
       "           0.022967,    0.022653,    0.022339,    0.022099,    0.021902,    0.021706,     0.02151,    0.020309,    0.018253,    0.017729,    0.017373,    0.017059,    0.016745,    0.016431,    0.016116,    0.015609,    0.014966,    0.014408,    0.014093,    0.013779,    0.013465,    0.013151,    0.012142,\n",
       "           0.011945,    0.011749,    0.011553,    0.011273,    0.010959,    0.010521,   0.0098108,   0.0092872,   0.0085476,   0.0081623,   0.0078482,   0.0075708,   0.0073464,    0.007122,   0.0068975,   0.0061258,   0.0059014,   0.0056769,   0.0054525,    0.005364,   0.0053082,   0.0049155,   0.0045912,\n",
       "           0.004557,   0.0045229,   0.0044887,   0.0044546,   0.0044204,   0.0043863,   0.0043521,    0.004318,   0.0042838,   0.0042497,   0.0042155,   0.0041814,   0.0041472,   0.0041131,   0.0040789,   0.0040448,   0.0040106,   0.0039765,   0.0039423,   0.0039082,    0.003874,   0.0038399,    0.003747,\n",
       "          0.0036348,   0.0035226,   0.0034104,   0.0032982,   0.0031859,   0.0030737,   0.0029684,   0.0028637,    0.002759,   0.0026543,   0.0025495,   0.0024448,   0.0023401,   0.0022671,   0.0022147,   0.0021624,     0.00211,   0.0020576,   0.0020053,   0.0019529,   0.0019005,   0.0018482,   0.0017958,\n",
       "          0.0017435,   0.0016911,   0.0016387,   0.0015864,    0.001534,   0.0014562,   0.0013776,   0.0012991,   0.0012205,    0.001142,   0.0010634,  0.00098489,  0.00090635,   0.0008278,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.23136178426556672)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.20302])\n",
       "names: {0: 'D40'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.5916974205812978), 'metrics/recall(B)': np.float64(0.45057471264367815), 'metrics/mAP50(B)': np.float64(0.48639451185768817), 'metrics/mAP50-95(B)': np.float64(0.20302481453310878), 'fitness': np.float64(0.23136178426556672)}\n",
       "save_dir: WindowsPath('d:/Pothole Vision - AI Road Damage Detection/runs/detect/yolov8m-D40')\n",
       "speed: {'preprocess': 0.27939100968029146, 'inference': 21.473926417685767, 'loss': 0.0009755186733685403, 'postprocess': 1.1052313969621674}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")  # Bisa ganti ke yolov8s.pt, yolov8m.pt, dll\n",
    "\n",
    "model.train(\n",
    "    data=\"yolo.yaml\",\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name=\"yolov8m-D40\",\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # evaluasi otomatis pada validation set yang didefinisikan di data.yaml\n",
    "print(metrics)  # lihat summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan evaluasi model\n",
    "metrics = model.val()  # TANPA confusion=True\n",
    "\n",
    "# Ambil confusion matrix (jika tersedia)\n",
    "if hasattr(metrics, \"confusion_matrix\"):\n",
    "    cm = metrics.confusion_matrix  # numpy array\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "else:\n",
    "    print(\"Confusion matrix tidak tersedia di metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "cm_matrix = cm.matrix  # Ambil array 2D dari ConfusionMatrix\n",
    "classes = model.names  # Misalnya: ['D40']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='.0f', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "for root, dirs, files in os.walk(target_dir):\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[1].lower() in image_extensions:\n",
    "            path = os.path.join(root, file)\n",
    "            print(f\"üñº Menampilkan: {file}\")\n",
    "            img = mpimg.imread(path)\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.imshow(img)\n",
    "            plt.title(file)\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = metrics.box.mp    # mean precision (float)\n",
    "mr = metrics.box.mr    # mean recall (float)\n",
    "map50 = metrics.box.map50  # mAP@0.5 (float)\n",
    "map5095 = metrics.box.map    # mAP@0.5:0.95 (float)\n",
    "f1_scores = metrics.box.f1  # list F1 score per kelas\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "\n",
    "print(f\"Precision (mean): {mp:.4f}\")\n",
    "print(f\"Recall (mean): {mr:.4f}\")\n",
    "print(f\"mAP@0.5: {map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {map5095:.4f}\")\n",
    "print(f\"F1-score (mean): {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model yang sudah kamu train\n",
    "model = YOLO('yolov8n.pt')  # sesuaikan path model terbaikmu\n",
    "\n",
    "# Fungsi untuk load gambar dari file input (misal file dialog atau path file langsung)\n",
    "def predict_from_file(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    # Resize lebih kecil agar lebih cepat\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    results = model(img_rgb)\n",
    "    \n",
    "    result_img = results[0].plot()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(result_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Contoh panggil fungsi dengan file input gambar\n",
    "predict_from_file(\"dataset-mix/train/images/United_States_000068.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
